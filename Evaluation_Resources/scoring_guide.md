# üéØ Guide de Notation et R√©ponses Attendues

Ce document fournit les r√©ponses attendues pour chaque question technique pos√©e lors des soutenances. Chaque r√©ponse est not√©e sur une √©chelle de 0 √† 5.

## üìä Bar√®me de Notation (0-5)

| Note | Description | Crit√®res |
| :--- | :--- | :--- |
| **0** | **Non R√©pondu / Hors Sujet** | L'√©tudiant ne sait pas r√©pondre ou donne une r√©ponse incoh√©rente. |
| **1** | **Tr√®s Insuffisant** | R√©ponse vague, manque de vocabulaire technique, incompr√©hension du concept. |
| **2** | **Insuffisant** | Comprend vaguement le concept mais incapable d'expliquer l'impl√©mentation ou le "pourquoi". |
| **3** | **Acceptable (Moyen)** | R√©ponse correcte mais basique. Sait "comment" mais pas forc√©ment "pourquoi" (ex: "J'ai utilis√© √ßa parce que c'√©tait dans le cours"). |
| **4** | **Bien** | Bonne compr√©hension technique et th√©orique. Explique clairement la d√©marche. |
| **5** | **Excellent** | Ma√Ætrise totale. Justifie le choix par rapport aux donn√©es, critique ses propres r√©sultats, propose des am√©liorations. |

---

## üìã Workflow Data Science Attendu (Tous Projets)

**Ordre correct des op√©rations :**
1. **Explorer** (EDA Initial)
2. **Nettoyer** (G√©rer NaNs, valeurs aberrantes, types)
3. **Split train/test** (Toujours avant le preprocessing avanc√©)
4. **Pr√©processer le train set** (Fit & Transform)
5. **Appliquer au test set** (Transform uniquement, utiliser les stats du train)
6. **SMOTE** (Seulement sur le Train Set transform√©)
7. **Mod√©liser & √âvaluer**

**R√©ponse Id√©ale pour les questions Workflow (5/5) :** "J'ai tout nettoy√© d'abord, puis splitt√©. J'ai ensuite calcul√© mes scalers/imputers sur le train set uniquement pour √©viter le Data Leakage, et j'ai appliqu√© SMOTE uniquement sur le train pour ne pas cr√©er de fausses donn√©es de test."

---

## 1. Projet 16 : Pr√©diction Box-Office

### Q0: EDA Initial
- **R√©ponse Id√©ale (5/5) :** "J'ai commenc√© par `df.info()` pour voir les types. J'ai trouv√© que Budget avait des 0 suspects, que Genre √©tait cat√©goriel, et que la distribution des recettes √©tait tr√®s skewed. J'ai aussi v√©rifi√© les NaN avec `df.isnull().sum()`."
- **R√©ponse M√©diocre (1/5) :** "J'ai juste regard√© les premi√®res lignes avec `head()`."

### Q1: Gestion des Budgets/Recettes nuls ou n√©gatifs
- **R√©ponse Id√©ale (5/5) :** "J'ai analys√© ces lignes. Comme un budget de 0 est impossible pour un film commercial, j'ai consid√©r√© cela comme une valeur manquante. J'ai soit supprim√© ces lignes (si peu nombreuses), soit remplac√© par la m√©diane du m√™me Genre."
- **R√©ponse M√©diocre (1/5) :** "Je n'ai rien fait" ou "J'ai mis 0".

### Q2: Feature Engineering (Dates)
- **R√©ponse Id√©ale (5/5) :** "Oui, j'ai extrait le mois. J'ai remarqu√© (via un barplot) que les films sortis en √ât√© (Juin/Juillet) et en D√©cembre ont des revenus moyens nettement sup√©rieurs."

### Q3: Encodage du Genre
- **R√©ponse Id√©ale (5/5) :** "J'ai utilis√© le One-Hot Encoding (`get_dummies`) car il n'y a pas d'ordre de grandeur entre 'Action' et 'Com√©die'. Un Label Encoding (1, 2, 3...) aurait fauss√© le mod√®le en introduisant une hi√©rarchie inexistante."

### Q4: Transformation Log du Budget
- **R√©ponse Id√©ale (5/5) :** "La distribution du budget est tr√®s √©tal√©e (skewed) avec quelques blockbusters √©normes. Le Log permet de 'tasser' ces valeurs extr√™mes et de rendre la distribution plus normale (gaussienne), ce qui aide l'algorithme √† mieux apprendre."

### Q5: Workflow (Split vs Imputation)
- **R√©ponse Id√©ale (5/5) :** "J'ai splitt√© d'abord. Si je calcule la m√©diane sur tout le dataset pour remplacer les 0, j'utilise des infos du futur (test set). Il faut calculer la m√©diane sur le train et l'appliquer au test."

### Q6: Score R¬≤ et Feature Importance
- **R√©ponse Id√©ale (5/5) :** "Mon R¬≤ est de 0.X (ex: 0.65). Le Feature Importance montre que le 'Budget' (ou Log_Budget) est de loin la variable la plus pr√©dictive, suivie par le nombre de votes ou le casting."

---

## 2. Projet 10 : Recommandation de Voyage

### Q0: EDA Initial
- **R√©ponse Id√©ale (5/5) :** "On a analys√© les types avec `df.info()`, trouv√© X% de NaN dans Budget_Quotidien, et observ√© que les notes suivent une distribution normale centr√©e sur 7."
- **R√©ponse M√©diocre (1/5) :** "On n'a pas vraiment explor√©, on a directement mod√©lis√©."

### Q1: Imputation du Budget_Quotidien
- **R√©ponse Id√©ale (5/5) :** "J'ai utilis√© la m√©diane car la moyenne est trop sensible aux valeurs extr√™mes (voyages de luxe). La m√©diane repr√©sente mieux le touriste typique."

### Q2: Relation Budget vs Note
- **R√©ponse Id√©ale (5/5) :** "Le scatterplot montre un nuage de points assez dispers√©. La corr√©lation est positive mais faible. Payer cher ne garantit pas une note de 10/10, d'autres facteurs comme le Climat jouent beaucoup."

### Q3: Encodage Style_Voyage
- **R√©ponse Id√©ale (5/5) :** "Oui, One-Hot Encoding. Comme un utilisateur peut aimer plusieurs styles, on a des colonnes binaires `Style_Aventure`, `Style_Luxe`, etc."

### Q4: Workflow (Split avant imputation)
- **R√©ponse Id√©ale (5/5) :** "Oui, on a fait le split d'abord. Sinon, la m√©diane calcul√©e inclurait des infos du test set, ce qui cr√©erait du data leakage et surestimerait nos performances."
- **R√©ponse M√©diocre (1/5) :** "On a tout imput√© avant le split" ou "Je ne sais pas pourquoi c'est important."

### Q5: Retrait ID Utilisateur
- **R√©ponse Id√©ale (5/5) :** "L'ID est un identifiant unique al√©atoire. Il n'a aucune valeur pr√©dictive. Si on le laisse, le mod√®le risque d'apprendre par coeur les IDs du train set et ne saura pas g√©n√©raliser aux nouveaux utilisateurs (Overfitting)."

### Q6: MAE et Interpr√©tation
- **R√©ponse Id√©ale (5/5) :** "Notre MAE est de 0.8. Cela signifie qu'en moyenne, notre pr√©diction de note se trompe de +/- 0.8 point sur une √©chelle de 10. C'est acceptable pour une recommandation."

---

## 3. Projet 06 : Fake News (NLP)

### Q0: EDA Initial
- **R√©ponse Id√©ale (5/5) :** "On a v√©rifi√© `df.info()`, trouv√© que toutes les colonnes sont du texte, pas de NaN. On a analys√© la distribution des longueurs de texte et le ratio Fake/Real."
- **R√©ponse M√©diocre (1/5) :** "On a juste charg√© les donn√©es et commenc√©."

### Q1: √âquilibre du Dataset
- **R√©ponse Id√©ale (5/5) :** "Il est relativement √©quilibr√© (ex: 60/40 ou 50/50). Je n'ai donc pas eu besoin d'utiliser de techniques complexes de r√©√©quilibrage comme SMOTE, l'accuracy reste une m√©trique valide."

### Q2: Word_Count Feature
- **R√©ponse Id√©ale (5/5) :** "Oui. J'ai observ√© que les Fake News ont tendance √† √™tre soit tr√®s courtes (juste une accroche), soit tr√®s longues (th√©ories du complot), alors que les vrais articles ont une longueur plus standard."

### Q3: Clickbait Detection
- **R√©ponse Id√©ale (5/5) :** "Les titres de Fake News utilisent beaucoup de MAJUSCULES et de '!!!'. J'ai chiffr√© √ßa avec une feature `Uppercase_Ratio`. C'est l'une des variables les plus discriminantes dans mon mod√®le."

### Q4: Workflow NLP (Data Leakage)
- **R√©ponse Id√©ale (5/5) :** "J'ai fait `vectorizer.fit_transform(X_train)` et `vectorizer.transform(X_test)`. Si je 'fit' sur tout avant le split, le mod√®le conna√Æt tous les mots du test set (vocabulaire), ce qui est de la triche."

### Q5: F1-Score vs Accuracy
- **R√©ponse Id√©ale (5/5) :** "L'Accuracy peut √™tre trompeuse. Le F1-Score est meilleur car il fait la moyenne harmonique entre Pr√©cision et Rappel. Ici, il est crucial de bien d√©tecter les Fake (Rappel) sans censurer les Vrais (Pr√©cision)."

### Q5: Matrice de Confusion et Gravit√©
- **R√©ponse Id√©ale (5/5) :** "Voici la matrice. On voit que j'ai 50 Faux N√©gatifs (Fake pr√©dits comme Vrais), ce qui est le plus dangereux car les fausses infos se propagent. Les Faux Positifs (Vrais censur√©s) sont aussi probl√©matiques mais moins critiques."

---

## 4. Projet 19 : Fraude Carte Cr√©dit

### Q0: EDA Initial & Nettoyage
- **R√©ponse Id√©ale (5/5) :** "J'ai check√© `df.info()` et trouv√© des incoh√©rences (ex: ' Class' avec un espace, ou des NaNs). J'ai nettoy√© tout √ßa en premier. Mod√©liser sur des donn√©es sales = √âchec garanti."
- **R√©ponse M√©diocre (1/5) :** "J'ai lanc√© SMOTE direct sans regarder les donn√©es, et j'ai eu des erreurs."

### Q1: Gestion du D√©s√©quilibre (Imbalanced)
- **R√©ponse Id√©ale (5/5) :** "C'est le point critique (3% de fraude). J'ai utilis√© SMOTE sur le train set uniquement pour g√©n√©rer des fraudes synth√©tiques et permettre au mod√®le de voir assez d'exemples positifs."

### Q2: Workflow SMOTE (Critique)
- **R√©ponse Id√©ale (5/5) :** "SMOTE doit √™tre fait **APR√àS** le split train/test et **UNIQUEMENT** sur le train set. Si on le fait avant, on cr√©e des copies de donn√©es qui se retrouvent dans le test set (Data Leakage), rendant le score final faux (trop optimiste)."
- **R√©ponse M√©diocre (1/5) :** "J'ai fait SMOTE sur tout le dataset avant le split."

### Q3: Features M√©tier (Night/Zscore)
- **R√©ponse Id√©ale (5/5) :** "J'ai cr√©√© `Is_Night` car les fraudes arrivent souvent la nuit. Le Z-Score aide √† d√©tecter les montants aberrants pour un client donn√© (ex: d√©penser 5000‚Ç¨ alors qu'on d√©pense d'habitude 50‚Ç¨)."

### Q4: Recall (Rappel) et Justification
- **R√©ponse Id√©ale (5/5) :** "Je vise un Recall > 0.85 pour la classe Fraude. C'est la priorit√© : il vaut mieux bloquer une transaction par erreur (Faux Positif = client m√©content) que de laisser passer une fraude de 10 000‚Ç¨ (Faux N√©gatif = perte s√®che)."

### Q5: Ajustement du Seuil
- **R√©ponse Id√©ale (5/5) :** "Par d√©faut le seuil est 0.5. Je l'ai baiss√© √† 0.3 pour √™tre plus agressif sur la d√©tection de fraude, ce qui a augment√© mon Recall de 10% (mais aussi les Faux Positifs)."

### Q6: Cost-Benefit Analysis (Bonus)
- **R√©ponse Id√©ale (5/5) :** "J'ai calcul√© le co√ªt total : `Co√ªt = (FP * 10) + (FN * 500)`. J'ai trac√© ce co√ªt pour diff√©rents seuils et choisi celui qui minimise la perte financi√®re totale (souvent autour de 0.1 ou 0.2)."
- **Pas de Bonus (0/5) :** L'√©tudiant n'a pas abord√© cette analyse.

---

## 5. Projet 07 : Gaspillage Alimentaire

### Q0: EDA Initial
- **R√©ponse Id√©ale (5/5) :** "On a explor√© avec `df.info()`, trouv√© que Price avait 15% de NaN, et que les dates de p√©remption √©taient au bon format. On a aussi visualis√© les ventes par jour de la semaine."
- **R√©ponse M√©diocre (1/5) :** "On n'a pas vraiment explor√© les donn√©es."

### Q1: Imputation Prix manquants
- **R√©ponse Id√©ale (5/5) :** "J'ai remplac√© les NaN par la m√©diane des prix *de ce produit sp√©cifique*. Remplacer par la moyenne globale aurait √©t√© faux car une pomme ne co√ªte pas le m√™me prix qu'un steak."

### Q2: Jours Avant Expiration
- **R√©ponse Id√©ale (5/5) :** "C'est une feature cl√©. Plus la date d'expiration approche, plus les ventes augmentent (souvent aid√©es par des promos 'date courte'). La corr√©lation est n√©gative (moins de jours = plus de ventes)."

### Q3: Feature Urgence_Vente
- **R√©ponse Id√©ale (5/5) :** "C'est une interaction : `Expire_Bientot * Promo_Forte`. C'est l√† que les volumes de ventes explosent. Le mod√®le capture tr√®s bien cet effet 'bon plan de derni√®re minute'."

### Q4: Workflow Imputation
- **R√©ponse Id√©ale (5/5) :** "On a fait le split d'abord, puis calcul√© la m√©diane par produit sur le train set, et appliqu√© ces m√™mes valeurs au test set."
- **R√©ponse M√©diocre (1/5) :** "On a imput√© sur tout le dataset."

### Q5: Pr√©dictions vs R√©el
- **R√©ponse Id√©ale (5/5) :** "Le mod√®le suit bien la tendance globale et les saisonnalit√©s hebdo (pics du samedi). Il a un peu plus de mal sur les pics extr√™mes de fin d'ann√©e."

---

## 6. Projet 08 : Sant√© Mentale

### Q0: EDA Initial
- **R√©ponse Id√©ale (5/5) :** "On a analys√© la distribution des 3 classes, trouv√© un l√©ger d√©s√©quilibre (40% Normal, 35% Anxious, 25% Depressed). On a aussi v√©rifi√© les textes vides et dupliqu√©s."
- **R√©ponse M√©diocre (1/5) :** "On a directement fait le mod√®le."

### Q1: Polarit√© (TextBlob)
- **R√©ponse Id√©ale (5/5) :** "La polarit√© va de -1 √† 1. Les tweets 'Depressed' ont une polarit√© tr√®s n√©gative (proche de -0.8), alors que 'Anxious' est parfois plus neutre mais avec beaucoup de subjectivit√©."

### Q2: Mots Cl√©s Sp√©cifiques
- **R√©ponse Id√©ale (5/5) :** "J'ai trouv√© que 'tired', 'alone', 'sleep' sont typiques de la d√©pression. Pour l'anxi√©t√©, c'est plut√¥t 'worry', 'scared', 'future', 'what if'."

### Q3: √âquilibre des classes
- **R√©ponse Id√©ale (5/5) :** "Les classes n'√©taient pas parfaitement √©quilibr√©es. On a utilis√© `class_weight='balanced'` dans le mod√®le pour compenser."

### Q4: Workflow NLP (Vocabulaire)
- **R√©ponse Id√©ale (5/5) :** "M√™me principe que pour le scaling : le vocabulaire doit √™tre construit uniquement sur les tweets du train set. Les mots inconnus du test set seront ignor√©s ou marqu√©s comme 'unknown'."

### Q5: Confusion Anxious/Depressed
- **R√©ponse Id√©ale (5/5) :** "Oui, il y a de la confusion car les sympt√¥mes se chevauchent. Le mod√®le distingue tr√®s bien 'Normal' des deux autres, mais a plus de mal √† s√©parer Anxi√©t√© et D√©pression."

### Q5: Syst√®me d'Alerte (Bonus)
- **R√©ponse Id√©ale (5/5) :** "J'ai fait un filtre simple : si le texte contient 'suicide', 'kill myself' ou 'die', le syst√®me l√®ve un drapeau rouge imm√©diat, quelle que soit la pr√©diction du mod√®le ML."

---

## 7. Projet X : Performance D√©veloppeurs AI

### Q0: EDA Initial
- **R√©ponse Id√©ale (5/5) :** "On a fait une heatmap de corr√©lation. On a vu que AI_Usage est corr√©l√© positivement avec Productivity jusqu'√† un certain point, et que Stress est n√©gativement corr√©l√© avec Success_Rate."
- **R√©ponse M√©diocre (1/5) :** "On n'a pas explor√©, on a juste entra√Æn√© le mod√®le."

### Q1: Relation AI Usage vs Productivit√©
- **R√©ponse Id√©ale (5/5) :** "Ce n'est pas lin√©aire. L'utilisation de l'IA augmente la productivit√© jusqu'√† un certain point (effet d'aide), mais trop d'usage (copier-coller sans comprendre) peut faire baisser la qualit√© ou le taux de succ√®s (courbe en cloche ou plateau)."

### Q2: Features Cr√©atives (Team de 4)
- **R√©ponse Id√©ale (5/5) :** "On a cr√©√© le ratio `Code_Efficiency = Lines_of_Code / Hours_Worked`. On a aussi combin√© `Stress_Level` et `AI_Usage` pour voir si l'IA r√©duit le stress."

### Q3: Workflow
- **R√©ponse Id√©ale (5/5) :** "Le preprocessing (scaling, encoding) a √©t√© fait apr√®s le split, en fittant sur le train set et en transformant le test set avec les m√™mes param√®tres."
- **R√©ponse M√©diocre (1/5) :** "On a tout normalis√© avant le split."

### Q4: RMSE Mod√®le R√©gression
- **R√©ponse Id√©ale (5/5) :** "Notre RMSE est de X. Cela veut dire qu'on pr√©dit le taux de succ√®s √† +/- X% pr√®s. Le RandomForest a mieux march√© que la R√©gression Lin√©aire car les relations ne sont pas lin√©aires."

### Q5: Classification Low/High
- **R√©ponse Id√©ale (5/5) :** "On a coup√© √† la m√©diane du `Task_Success_Rate` pour avoir deux classes √©quilibr√©es. Ce qui distingue les 'High Performers', c'est souvent l'exp√©rience coupl√©e √† un usage mod√©r√© et intelligent de l'IA."

### Q6: Risque Burnout (Bonus)
- **R√©ponse Id√©ale (5/5) :** "Les profils √† risque sont ceux qui combinent `High Hours` + `High Stress`. Paradoxalement, ceux qui n'utilisent PAS du tout l'IA semblent plus stress√©s car ils font tout manuellement."

### Q7: Synth√®se IA
- **R√©ponse Id√©ale (5/5) :** "L'IA est un multiplicateur de force pour les seniors, mais peut √™tre une b√©quille risqu√©e pour les juniors s'ils ne v√©rifient pas le code. Il faut encourager l'usage supervis√©."
