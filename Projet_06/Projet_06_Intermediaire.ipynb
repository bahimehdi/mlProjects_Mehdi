{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25839dda",
   "metadata": {},
   "source": [
    "\n",
    "# üì∞ Projet 6 : Classificateur de Fake News\n",
    "## Version Interm√©diaire - \"Voici le chemin, marche seul\"\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ L'Objectif de ce Projet\n",
    "\n",
    "La d√©sinformation se propage plus vite que la v√©rit√©. Votre mission est de **construire un syst√®me de d√©tection de fake news** en analysant le titre, le contenu textuel, et les patterns de partage.\n",
    "\n",
    "**Comp√©tences vis√©es :**\n",
    "- NLP (Natural Language Processing) pour extraire des features textuelles\n",
    "- Feature engineering cr√©atif pour d√©tecter les patterns de clickbait\n",
    "- Classification binaire avec m√©triques adapt√©es\n",
    "- Analyse exploratoire des comportements viraux\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d174a7a",
   "metadata": {},
   "source": [
    "\n",
    "# üìã SESSION 1 : From Raw Data to Clean Insights (45 min)\n",
    "\n",
    "## Part 1: The Setup (10 min)\n",
    "\n",
    "### √âtape 1.1: Imports et Configuration\n",
    "\n",
    "**Objectif:** Importer les biblioth√®ques n√©cessaires pour le NLP et la visualisation.\n",
    "\n",
    "**Librairies recommand√©es:**\n",
    "- `pandas`, `numpy` : Manipulation de donn√©es\n",
    "- `matplotlib`, `seaborn` : Visualisations\n",
    "- `re` : Expressions r√©guli√®res pour analyser le texte\n",
    "- (Optionnel) `nltk` ou `textblob` : Analyse de sentiment\n",
    "\n",
    "**Conseil:** Configurez `matplotlib` avec une taille de figure par d√©faut (10, 6) pour de meilleurs graphiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30089fe",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 1.2: Chargement des Donn√©es\n",
    "\n",
    "**Objectif:** Charger `fake_news.csv` et explorer la structure.\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Affichage des 5 premi√®res lignes\n",
    "- Dimensions du dataset (lignes √ó colonnes)\n",
    "- Types de donn√©es de chaque colonne\n",
    "- Liste des noms de colonnes\n",
    "\n",
    "**Conseil:** Utilisez `df.info()` pour avoir un aper√ßu complet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93754ae3",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: The Sanity Check (15 min)\n",
    "\n",
    "### √âtape 2.1: Analyse de la Distribution de la Cible\n",
    "\n",
    "**Objectif:** V√©rifier l'√©quilibre des classes `Etiquette` (Real vs Fake).\n",
    "\n",
    "**Approches recommand√©es:**\n",
    "- `value_counts()` avec normalisation pour voir les pourcentages\n",
    "- **Visualisation:** Countplot ou barplot pour comparer visuellement\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Nombre et pourcentage de Real vs Fake\n",
    "- Graphique de distribution\n",
    "- **D√©cision:** Le dataset est-il √©quilibr√© ? (> 30% pour chaque classe = √©quilibr√©)\n",
    "\n",
    "**Conseil:** Si fortement d√©s√©quilibr√© (< 20% d'une classe), noter pour plus tard l'utilisation de SMOTE ou class_weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218de12f",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 2.2: D√©tection des Valeurs Manquantes\n",
    "\n",
    "**Objectif:** Identifier et traiter les NaN dans les colonnes textuelles.\n",
    "\n",
    "**Approches recommand√©es:**\n",
    "1. **V√©rification:** `df.isnull().sum()` pour compter les NaN\n",
    "2. **Traitement:**\n",
    "   - Supprimer les lignes avec texte manquant (`dropna`) si < 5% du dataset\n",
    "   - Remplacer par cha√Æne vide si n√©cessaire\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Rapport des NaN par colonne\n",
    "- Dataset nettoy√© (nombre de lignes avant/apr√®s)\n",
    "\n",
    "**Conseil:** Pour NLP, il vaut mieux supprimer que remplir avec du texte g√©n√©rique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec724ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d8a9b",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 2.3: D√©tection des Duplicatas\n",
    "\n",
    "**Objectif:** Supprimer les articles en double.\n",
    "\n",
    "**Approche:**\n",
    "- Utiliser `df.duplicated().sum()` puis `df.drop_duplicates()`\n",
    "- **Alternative:** Ne consid√©rer que le texte (`subset=['Title', 'Corps_Texte']`)\n",
    "\n",
    "**Livrable attendu:** Nombre de duplicatas trouv√©s et supprim√©s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67a4ac",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Exploratory Data Analysis (20 min)\n",
    "\n",
    "### √âtape 3.1: Analyse des Partages\n",
    "\n",
    "**Objectif:** Comparer le comportement de partage entre Real et Fake news.\n",
    "\n",
    "**Approches recommand√©es:**\n",
    "1. **Boxplot:** `sns.boxplot(x='Etiquette', y='Nb_Partages')` avec √©chelle log (`plt.yscale('log')`)\n",
    "2. **Statistiques descriptives:** `df.groupby('Etiquette')['Nb_Partages'].describe()`\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Graphique comparatif\n",
    "- **Insight:** Les fake news ont-elles plus ou moins de partages en moyenne ?\n",
    "\n",
    "**Conseil:** L'√©chelle log aide √† visualiser des donn√©es qui varient de 0 √† 1 million.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1b7ae",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 3.2: Analyse de la Longueur du Texte\n",
    "\n",
    "**Objectif:** Comparer la longueur des titres et corps de texte entre Real et Fake.\n",
    "\n",
    "**Approches recommand√©es:**\n",
    "1. Cr√©er des features temporaires :\n",
    "   - `Title_Length = df['Title'].apply(len)`\n",
    "   - `Body_Length = df['Corps_Texte'].apply(len)`\n",
    "2. Visualiser avec histogrammes (`hue='Etiquette'`) ou boxplots\n",
    "\n",
    "**Livrables attendus:**\n",
    "- 2 graphiques (un pour Title, un pour Body)\n",
    "- **Insight:** Les fake news ont-elles des titres plus courts/longs ? Texte plus court/long ?\n",
    "\n",
    "**Conseil:** Les fake news ont souvent des titres sensationnalistes courts et un contenu superficiel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ff506",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 3.3: Exploration des Sources\n",
    "\n",
    "**Objectif:** Identifier si certaines sources (URLs) sont plus associ√©es aux fake news.\n",
    "\n",
    "**Approches:**\n",
    "1. Extraire le domaine principal de `URL_Source` (ex: \"cnn.com\" depuis \"https://cnn.com/article\")\n",
    "2. Compter les articles par source\n",
    "3. Croiser avec `Etiquette`\n",
    "\n",
    "**Livrable attendu:** Top 5 sources et leur ratio Fake/Real\n",
    "\n",
    "**Conseil (Avanc√©):** Utilisez `urlparse` de la librairie `urllib.parse` ou regex pour extraire le domaine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9878a",
   "metadata": {},
   "source": [
    "\n",
    "# üìã SESSION 2 : The Art of Feature Engineering (45 min)\n",
    "\n",
    "## Part 1: The Concept (10 min)\n",
    "\n",
    "Les mod√®les de ML ne lisent pas le texte. Vous devez transformer le langage naturel en **vecteurs num√©riques**.\n",
    "\n",
    "**Strat√©gies disponibles:**\n",
    "1. **Features statistiques** : Longueur, nombre de mots, ponctuation\n",
    "2. **Features linguistiques** : Sentiment, complexit√©, clickbait indicators\n",
    "3. **Vectorisation** : TF-IDF, Count Vectorizer, Word Embeddings (avanc√©)\n",
    "\n",
    "## Part 2: The Lab - Choose Your Recipe (30 min)\n",
    "\n",
    "### Recipe 3: Text & NLP Features\n",
    "\n",
    "#### √âtape 2.1: Features Statistiques du Titre\n",
    "\n",
    "**Objectif:** Cr√©er des features num√©riques bas√©es sur le `Title`.\n",
    "\n",
    "**Features recommand√©es:**\n",
    "1. **Word Count** : `len(text.split())`\n",
    "2. **Character Count** : `len(text)`\n",
    "3. **Average Word Length** : `sum(len(word) for word in text.split()) / word_count`\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Colonnes : `Title_Word_Count`, `Title_Char_Count`, `Title_Avg_Word_Length`\n",
    "- V√©rification : afficher les 5 premi√®res lignes avec ces colonnes\n",
    "\n",
    "**Conseil:** Utilisez `df['Title'].apply(lambda x: ...)` pour appliquer une fonction √† chaque ligne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdba9ff",
   "metadata": {},
   "source": [
    "\n",
    "#### √âtape 2.2: Features Statistiques du Corps de Texte\n",
    "\n",
    "**Objectif:** R√©p√©ter la m√™me analyse pour `Corps_Texte`.\n",
    "\n",
    "**Features √† cr√©er:**\n",
    "- `Body_Word_Count`\n",
    "- `Body_Char_Count`\n",
    "- `Body_Avg_Word_Length`\n",
    "\n",
    "**Livrable attendu:** 3 nouvelles colonnes v√©rifi√©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5adba6",
   "metadata": {},
   "source": [
    "\n",
    "### Recipe 6: Domain-Specific Features (Clickbait Detection)\n",
    "\n",
    "#### √âtape 2.3: Indicateurs de Clickbait\n",
    "\n",
    "**Objectif:** D√©tecter les titres sensationnalistes typiques des fake news.\n",
    "\n",
    "**Features recommand√©es:**\n",
    "1. **Exclamation Count** : `text.count('!')`\n",
    "2. **Question Mark Count** : `text.count('?')`\n",
    "3. **Uppercase Ratio** : `sum(1 for c in text if c.isupper()) / len(text)`\n",
    "4. **Has Numbers** : `1 if re.search(r'\\d', text) else 0`\n",
    "5. **All Caps Words** : Nombre de mots enti√®rement en majuscules\n",
    "\n",
    "**Approches multiples:**\n",
    "- **M√©thode 1 (Simple):** Analyse caract√®re par caract√®re\n",
    "- **M√©thode 2 (Regex):** Utiliser `re.findall(r'\\b[A-Z]+\\b', text)` pour d√©tecter mots en majuscules\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Minimum 3 features clickbait (exclamation, uppercase ratio, numbers)\n",
    "- Feature composite : `Title_Is_Clickbait` (1 si >= 3 exclamations OU uppercase_ratio > 0.5)\n",
    "\n",
    "**Conseil:** Les fake news utilisent souvent \"SHOCKING!!!\" ou \"YOU WON'T BELIEVE!!!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd0eec",
   "metadata": {},
   "source": [
    "\n",
    "#### √âtape 2.4: Ratio Partages/Longueur (Bot Detection Proxy)\n",
    "\n",
    "**Objectif:** Cr√©er une feature pour d√©tecter les partages artificiels.\n",
    "\n",
    "**Hypoth√®se:** Un article tr√®s court avec √©norm√©ment de partages est suspect (bots).\n",
    "\n",
    "**Feature √† cr√©er:**\n",
    "```\n",
    "Share_Per_Word = Nb_Partages / (Body_Word_Count + 1)\n",
    "```\n",
    "\n",
    "**Livrable attendu:** Nouvelle colonne `Share_Per_Word`\n",
    "\n",
    "**Conseil:** Ajoutez +1 au d√©nominateur pour √©viter division par z√©ro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae03911",
   "metadata": {},
   "source": [
    "\n",
    "### Recipe 4: Math Magic (Transformations)\n",
    "\n",
    "#### √âtape 2.5: Log Transformation des Partages\n",
    "\n",
    "**Objectif:** Normaliser la distribution de `Nb_Partages`.\n",
    "\n",
    "**Approches:**\n",
    "1. **Log naturel** : `np.log1p(x)` (log(x+1) pour g√©rer les 0)\n",
    "2. **Square Root** : `np.sqrt(x)` (alternative plus douce)\n",
    "\n",
    "**Livrable attendu:** Colonne `Nb_Partages_Log`\n",
    "\n",
    "**Conseil:** La transformation log r√©duit l'impact des valeurs extr√™mes (1M partages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88a895",
   "metadata": {},
   "source": [
    "\n",
    "#### √âtape 2.6: Bucketization (Cat√©gorisation des Partages)\n",
    "\n",
    "**Objectif:** Cr√©er des buckets de viralit√©.\n",
    "\n",
    "**Cat√©gories sugg√©r√©es:**\n",
    "- 'Viral' : > 10,000 partages\n",
    "- 'Popular' : 1,000 - 10,000\n",
    "- 'Low' : < 1,000\n",
    "\n",
    "**Approche:** Fonction conditionnelle ou `pd.cut()`\n",
    "\n",
    "**Livrable attendu:** Colonne `Share_Bucket` (optionnel: encoder en 0/1/2)\n",
    "\n",
    "**Conseil:** Cette feature peut √™tre utilis√©e pour une analyse secondaire (pas pour le mod√®le principal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925019ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4220648",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Final Prep (5 min)\n",
    "\n",
    "### √âtape 2.7: Encodage de la Cible\n",
    "\n",
    "**Objectif:** Transformer `Etiquette` (Real/Fake) en valeurs num√©riques (0/1).\n",
    "\n",
    "**Approches:**\n",
    "1. **Lambda:** `df['Etiquette'].apply(lambda x: 1 if x == 'Fake' else 0)`\n",
    "2. **LabelEncoder:** `from sklearn.preprocessing import LabelEncoder`\n",
    "\n",
    "**Livrable attendu:** Colonne `Etiquette_Encoded` avec 0=Real, 1=Fake\n",
    "\n",
    "**Conseil:** Toujours v√©rifier la distribution apr√®s encodage (`value_counts()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86cce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f49d67",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 2.8: S√©lection des Features\n",
    "\n",
    "**Objectif:** Cr√©er X (features) et y (target) pour le mod√®le.\n",
    "\n",
    "**Features recommand√©es pour le mod√®le:**\n",
    "- Toutes les features statistiques (word count, char count, etc.)\n",
    "- Toutes les features clickbait (exclamation, uppercase, etc.)\n",
    "- `Nb_Partages_Log`\n",
    "- (Optionnel) `Share_Per_Word`\n",
    "\n",
    "**√Ä EXCLURE:**\n",
    "- Colonnes textuelles originales (`Title`, `Corps_Texte`, `URL_Source`)\n",
    "- `ID_Article`\n",
    "- `Etiquette` (original, non encod√©e)\n",
    "- `Nb_Partages` (utiliser la version log)\n",
    "\n",
    "**Livrables attendus:**\n",
    "- `X` : DataFrame avec features num√©riques uniquement\n",
    "- `y` : Series avec `Etiquette_Encoded`\n",
    "- V√©rification : `X.shape` et `y.shape`\n",
    "\n",
    "**Conseil:** Cr√©ez une liste `feature_columns` puis faites `X = df[feature_columns]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6310f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba106ca1",
   "metadata": {},
   "source": [
    "\n",
    "# üìã SESSION 3 : Building & Trusting Your Model (45 min)\n",
    "\n",
    "## Part 1: The Split (10 min)\n",
    "\n",
    "### √âtape 3.1: Train/Test Split\n",
    "\n",
    "**Objectif:** Diviser les donn√©es pour entra√Ænement et √©valuation.\n",
    "\n",
    "**Approches recommand√©es:**\n",
    "- **Standard:** 80% train, 20% test\n",
    "- **Avec Stratification:** `stratify=y` pour garder la m√™me proportion de classes dans train et test\n",
    "\n",
    "**Param√®tres cl√©s:**\n",
    "- `test_size=0.2`\n",
    "- `random_state=42` (pour reproductibilit√©)\n",
    "- `stratify=y` (IMPORTANT pour classification)\n",
    "\n",
    "**Livrables attendus:**\n",
    "- `X_train, X_test, y_train, y_test`\n",
    "- Affichage des tailles (nombre de lignes)\n",
    "- V√©rification de la distribution des classes dans train et test\n",
    "\n",
    "**Conseil:** Utilisez `y_train.value_counts(normalize=True)` pour v√©rifier les proportions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411c657",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Training (15 min)\n",
    "\n",
    "### √âtape 3.2: Entra√Ænement du Mod√®le\n",
    "\n",
    "**Objectif:** Entra√Æner un classificateur pour d√©tecter les fake news.\n",
    "\n",
    "**Mod√®les recommand√©s:**\n",
    "1. **RandomForestClassifier** ‚úÖ Recommand√©\n",
    "   - Robuste, g√®re bien les features multiples\n",
    "   - Param√®tres : `n_estimators=100`, `random_state=42`\n",
    "   - Avantage : Peut fournir l'importance des features\n",
    "\n",
    "2. **LogisticRegression** (Alternative)\n",
    "   - Plus rapide, interpr√©table\n",
    "   - Bon pour baseline\n",
    "\n",
    "3. **GradientBoostingClassifier** (Avanc√©)\n",
    "   - Meilleure performance potentielle\n",
    "   - Plus lent √† entra√Æner\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Mod√®le entra√Æn√© et sauvegard√© dans une variable `model`\n",
    "- Message de confirmation d'entra√Ænement\n",
    "\n",
    "**Conseil:** RandomForest avec 100 arbres est un bon √©quilibre performance/vitesse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167853da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85f056",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Evaluation (20 min)\n",
    "\n",
    "### Contexte M√©tier\n",
    "\n",
    "**Type de probl√®me:** Classification binaire √©quilibr√©e (~60% Real, ~40% Fake)\n",
    "\n",
    "**M√©triques prioritaires:**\n",
    "1. **F1-Score** ‚Üê PRIORIT√â (√©quilibre pr√©cision/rappel)\n",
    "2. **Accuracy** (acceptable car classes relativement √©quilibr√©es)\n",
    "3. **Confusion Matrix** (pour comprendre les types d'erreurs)\n",
    "\n",
    "**Pourquoi F1 > Accuracy ?**\n",
    "- Bloquer une vraie news (Faux Positif) = Censure\n",
    "- Laisser passer une fake news (Faux N√©gatif) = D√©sinformation\n",
    "- Les deux erreurs sont graves ‚Üí F1 √©quilibre les deux\n",
    "\n",
    "### √âtape 3.3: Calcul des M√©triques\n",
    "\n",
    "**Objectif:** √âvaluer la performance du mod√®le.\n",
    "\n",
    "**M√©triques √† calculer:**\n",
    "- `accuracy_score(y_test, y_pred)`\n",
    "- `f1_score(y_test, y_pred)` ‚Üê **PRIORIT√â**\n",
    "- `classification_report(y_test, y_pred, target_names=['Real', 'Fake'])`\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Accuracy (pourcentage)\n",
    "- F1-Score (0.0 √† 1.0)\n",
    "- Rapport complet (Precision, Recall, F1 par classe)\n",
    "\n",
    "**Conseil:** Un F1-Score > 0.75 est bon, > 0.85 est excellent pour ce type de probl√®me.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759bd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aa29c",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 3.4: Matrice de Confusion\n",
    "\n",
    "**Objectif:** Visualiser les types d'erreurs du mod√®le.\n",
    "\n",
    "**Interpr√©tation:**\n",
    "```\n",
    "                Pr√©dit Real    Pr√©dit Fake\n",
    "Vrai Real       [TN]           [FP] ‚Üê Censure (bad)\n",
    "Vrai Fake       [FN] ‚Üê D√©sinformation (bad)  [TP]\n",
    "```\n",
    "\n",
    "**Approche:**\n",
    "- Calculer avec `confusion_matrix(y_test, y_pred)`\n",
    "- Visualiser avec `sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')`\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Graphique de la matrice\n",
    "- Interpr√©tation : Nombre de FP et FN\n",
    "\n",
    "**Conseil:** Ajoutez les labels `xticklabels` et `yticklabels` pour clarifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740802a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe5b49",
   "metadata": {},
   "source": [
    "\n",
    "### √âtape 3.5: Feature Importance\n",
    "\n",
    "**Objectif:** Identifier quelles features aident le plus √† d√©tecter les fake news.\n",
    "\n",
    "**Approche (pour RandomForest):**\n",
    "```python\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "```\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Dataframe tri√© par importance\n",
    "- Barplot horizontal (`sns.barplot`)\n",
    "- **Insight:** Quelle est la feature la plus importante ?\n",
    "\n",
    "**Conseil:** Si `Nb_Partages_Log` domine, essayez de retirer cette feature et r√©-entra√Æner pour voir l'impact du texte seul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79526b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e1aaa",
   "metadata": {},
   "source": [
    "\n",
    "## üéÅ Part 4: Going Further (Bonus - 15-30 mins)\n",
    "\n",
    "### Bonus Task 1: Extraction des Mots-Cl√©s de Fake News\n",
    "\n",
    "**Goal:** Identifier les mots les plus fr√©quents dans les titres de fake news.\n",
    "\n",
    "**Why it matters:** Comprendre le vocabulaire utilis√© permet de cr√©er des r√®gles de filtrage automatiques.\n",
    "\n",
    "**Approche:**\n",
    "1. Filtrer les articles o√π `Etiquette == 'Fake'`\n",
    "2. Concat√©ner tous les titres en un seul texte\n",
    "3. Convertir en minuscules et splitter par espaces\n",
    "4. Utiliser `collections.Counter` pour compter les mots\n",
    "5. (Optionnel) Retirer les stop words (\"the\", \"a\", \"is\")\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Top 10 des mots dans les fake news\n",
    "- (Bonus) Comparaison avec top 10 des real news\n",
    "\n",
    "**Conseil:** La librairie `nltk` offre une liste de stop words en anglais : `nltk.corpus.stopwords.words('english')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29774bd4",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Task 2: D√©tection de Patterns Bot-like\n",
    "\n",
    "**Goal:** Identifier les articles avec un ratio partages/longueur anormalement √©lev√©.\n",
    "\n",
    "**Why it matters:** Les bots partagent massivement sans lire le contenu. Un article court avec √©norm√©ment de partages est suspect.\n",
    "\n",
    "**Approche:**\n",
    "1. Utiliser la feature `Share_Per_Word` cr√©√©e en Session 2\n",
    "2. Calculer le 95e percentile : `df['Share_Per_Word'].quantile(0.95)`\n",
    "3. Marquer les articles au-dessus de ce seuil comme \"Bot-like\"\n",
    "4. Analyser la distribution Real/Fake dans ce groupe\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Seuil calcul√©\n",
    "- Nombre d'articles suspects\n",
    "- Crosstab : Bot-like √ó Etiquette\n",
    "- **Insight:** Les fake news sont-elles plus souvent bot-like ?\n",
    "\n",
    "**Conseil:** Cr√©ez une colonne binaire `Is_Bot_Like` pour faciliter l'analyse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd1d26",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Task 3: Pr√©diction de Viralit√© (R√©gression)\n",
    "\n",
    "**Goal:** Construire un mod√®le pour pr√©dire le nombre de partages d'un article.\n",
    "\n",
    "**Why it matters:** Comprendre ce qui rend un contenu viral aide les cr√©ateurs de contenu l√©gitime √† maximiser leur impact.\n",
    "\n",
    "**Approche:**\n",
    "1. Changer la cible : `y_viral = df['Nb_Partages_Log']`\n",
    "2. Features : Toutes sauf `Nb_Partages` et `Nb_Partages_Log`\n",
    "3. Mod√®le : `RandomForestRegressor`\n",
    "4. M√©triques : MAE, RMSE, R¬≤\n",
    "\n",
    "**Livrables attendus:**\n",
    "- Mod√®le de r√©gression entra√Æn√©\n",
    "- MAE et R¬≤ Score\n",
    "- (Bonus) Scatter plot des pr√©dictions vs valeurs r√©elles\n",
    "\n",
    "**Conseil:** Un R¬≤ > 0.5 serait d√©j√† bon pour ce type de pr√©diction (comportement viral impr√©visible).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06908f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae1a2c",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Task 4: Topic Clustering (Regroupement par Sujet)\n",
    "\n",
    "**Goal:** Grouper automatiquement les articles en cat√©gories th√©matiques (ex: Politique, Sant√©, C√©l√©brit√©s).\n",
    "\n",
    "**Why it matters:** Les fake news se concentrent souvent sur des sujets sensibles (sant√©, politique). Identifier les topics permet une analyse cibl√©e.\n",
    "\n",
    "**Approche (Avanc√©e):**\n",
    "1. **Vectorisation TF-IDF:**\n",
    "   - `from sklearn.feature_extraction.text import TfidfVectorizer`\n",
    "   - `vectorizer = TfidfVectorizer(max_features=50, stop_words='english')`\n",
    "   - `X_tfidf = vectorizer.fit_transform(df['Title'])`\n",
    "\n",
    "2. **Clustering KMeans:**\n",
    "   - `from sklearn.cluster import KMeans`\n",
    "   - `kmeans = KMeans(n_clusters=3, random_state=42)`\n",
    "   - `df['Topic_Cluster'] = kmeans.fit_predict(X_tfidf)`\n",
    "\n",
    "3. **Analyse:**\n",
    "   - Afficher quelques exemples de titres par cluster\n",
    "   - Croiser avec `Etiquette` pour voir si certains topics sont plus fake\n",
    "\n",
    "**Livrables attendus:**\n",
    "- 3-5 clusters cr√©√©s\n",
    "- Exemples de titres par cluster\n",
    "- Distribution Fake/Real par cluster\n",
    "- **Interpr√©tation:** Nommer les clusters (ex: \"Cluster 0 = Politique\")\n",
    "\n",
    "**Conseil:** Commencez avec 3 clusters, puis augmentez si n√©cessaire. Analysez les top mots de chaque cluster avec `vectorizer.get_feature_names_out()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
