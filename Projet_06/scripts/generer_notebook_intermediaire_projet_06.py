import nbformat as nbf

def generer_notebook_intermediaire():
    nb = nbf.v4.new_notebook()
    
    cells = []
    
    # Titre et Introduction
    cells.append(nbf.v4.new_markdown_cell("""
# üì∞ Projet 6 : Classificateur de Fake News
## Version Interm√©diaire - "Voici le chemin, marche seul"

---

### üéØ L'Objectif de ce Projet

La d√©sinformation se propage plus vite que la v√©rit√©. Votre mission est de **construire un syst√®me de d√©tection de fake news** en analysant le titre, le contenu textuel, et les patterns de partage.

**Comp√©tences vis√©es :**
- NLP (Natural Language Processing) pour extraire des features textuelles
- Feature engineering cr√©atif pour d√©tecter les patterns de clickbait
- Classification binaire avec m√©triques adapt√©es
- Analyse exploratoire des comportements viraux

---
"""))

    # --- SESSION 1 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 1 : From Raw Data to Clean Insights (45 min)

## Part 1: The Setup (10 min)

### √âtape 1.1: Imports et Configuration

**Objectif:** Importer les biblioth√®ques n√©cessaires pour le NLP et la visualisation.

**Librairies recommand√©es:**
- `pandas`, `numpy` : Manipulation de donn√©es
- `matplotlib`, `seaborn` : Visualisations
- `re` : Expressions r√©guli√®res pour analyser le texte
- (Optionnel) `nltk` ou `textblob` : Analyse de sentiment

**Conseil:** Configurez `matplotlib` avec une taille de figure par d√©faut (10, 6) pour de meilleurs graphiques.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 1.2: Chargement des Donn√©es

**Objectif:** Charger `fake_news.csv` et explorer la structure.

**Livrables attendus:**
- Affichage des 5 premi√®res lignes
- Dimensions du dataset (lignes √ó colonnes)
- Types de donn√©es de chaque colonne
- Liste des noms de colonnes

**Conseil:** Utilisez `df.info()` pour avoir un aper√ßu complet.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: The Sanity Check (15 min)

### √âtape 2.1: Analyse de la Distribution de la Cible

**Objectif:** V√©rifier l'√©quilibre des classes `Etiquette` (Real vs Fake).

**Approches recommand√©es:**
- `value_counts()` avec normalisation pour voir les pourcentages
- **Visualisation:** Countplot ou barplot pour comparer visuellement

**Livrables attendus:**
- Nombre et pourcentage de Real vs Fake
- Graphique de distribution
- **D√©cision:** Le dataset est-il √©quilibr√© ? (> 30% pour chaque classe = √©quilibr√©)

**Conseil:** Si fortement d√©s√©quilibr√© (< 20% d'une classe), noter pour plus tard l'utilisation de SMOTE ou class_weight.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 2.2: D√©tection des Valeurs Manquantes

**Objectif:** Identifier et traiter les NaN dans les colonnes textuelles.

**Approches recommand√©es:**
1. **V√©rification:** `df.isnull().sum()` pour compter les NaN
2. **Traitement:**
   - Supprimer les lignes avec texte manquant (`dropna`) si < 5% du dataset
   - Remplacer par cha√Æne vide si n√©cessaire

**Livrables attendus:**
- Rapport des NaN par colonne
- Dataset nettoy√© (nombre de lignes avant/apr√®s)

**Conseil:** Pour NLP, il vaut mieux supprimer que remplir avec du texte g√©n√©rique.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 2.3: D√©tection des Duplicatas

**Objectif:** Supprimer les articles en double.

**Approche:**
- Utiliser `df.duplicated().sum()` puis `df.drop_duplicates()`
- **Alternative:** Ne consid√©rer que le texte (`subset=['Title', 'Corps_Texte']`)

**Livrable attendu:** Nombre de duplicatas trouv√©s et supprim√©s
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Exploratory Data Analysis (20 min)

### √âtape 3.1: Analyse des Partages

**Objectif:** Comparer le comportement de partage entre Real et Fake news.

**Approches recommand√©es:**
1. **Boxplot:** `sns.boxplot(x='Etiquette', y='Nb_Partages')` avec √©chelle log (`plt.yscale('log')`)
2. **Statistiques descriptives:** `df.groupby('Etiquette')['Nb_Partages'].describe()`

**Livrables attendus:**
- Graphique comparatif
- **Insight:** Les fake news ont-elles plus ou moins de partages en moyenne ?

**Conseil:** L'√©chelle log aide √† visualiser des donn√©es qui varient de 0 √† 1 million.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 3.2: Analyse de la Longueur du Texte

**Objectif:** Comparer la longueur des titres et corps de texte entre Real et Fake.

**Approches recommand√©es:**
1. Cr√©er des features temporaires :
   - `Title_Length = df['Title'].apply(len)`
   - `Body_Length = df['Corps_Texte'].apply(len)`
2. Visualiser avec histogrammes (`hue='Etiquette'`) ou boxplots

**Livrables attendus:**
- 2 graphiques (un pour Title, un pour Body)
- **Insight:** Les fake news ont-elles des titres plus courts/longs ? Texte plus court/long ?

**Conseil:** Les fake news ont souvent des titres sensationnalistes courts et un contenu superficiel.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 3.3: Exploration des Sources

**Objectif:** Identifier si certaines sources (URLs) sont plus associ√©es aux fake news.

**Approches:**
1. Extraire le domaine principal de `URL_Source` (ex: "cnn.com" depuis "https://cnn.com/article")
2. Compter les articles par source
3. Croiser avec `Etiquette`

**Livrable attendu:** Top 5 sources et leur ratio Fake/Real

**Conseil (Avanc√©):** Utilisez `urlparse` de la librairie `urllib.parse` ou regex pour extraire le domaine.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    # --- SESSION 2 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 2 : The Art of Feature Engineering (45 min)

## Part 1: The Concept (10 min)

Les mod√®les de ML ne lisent pas le texte. Vous devez transformer le langage naturel en **vecteurs num√©riques**.

**Strat√©gies disponibles:**
1. **Features statistiques** : Longueur, nombre de mots, ponctuation
2. **Features linguistiques** : Sentiment, complexit√©, clickbait indicators
3. **Vectorisation** : TF-IDF, Count Vectorizer, Word Embeddings (avanc√©)

## Part 2: The Lab - Choose Your Recipe (30 min)

### Recipe 3: Text & NLP Features

#### √âtape 2.1: Features Statistiques du Titre

**Objectif:** Cr√©er des features num√©riques bas√©es sur le `Title`.

**Features recommand√©es:**
1. **Word Count** : `len(text.split())`
2. **Character Count** : `len(text)`
3. **Average Word Length** : `sum(len(word) for word in text.split()) / word_count`

**Livrables attendus:**
- Colonnes : `Title_Word_Count`, `Title_Char_Count`, `Title_Avg_Word_Length`
- V√©rification : afficher les 5 premi√®res lignes avec ces colonnes

**Conseil:** Utilisez `df['Title'].apply(lambda x: ...)` pour appliquer une fonction √† chaque ligne.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.2: Features Statistiques du Corps de Texte

**Objectif:** R√©p√©ter la m√™me analyse pour `Corps_Texte`.

**Features √† cr√©er:**
- `Body_Word_Count`
- `Body_Char_Count`
- `Body_Avg_Word_Length`

**Livrable attendu:** 3 nouvelles colonnes v√©rifi√©es
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### Recipe 6: Domain-Specific Features (Clickbait Detection)

#### √âtape 2.3: Indicateurs de Clickbait

**Objectif:** D√©tecter les titres sensationnalistes typiques des fake news.

**Features recommand√©es:**
1. **Exclamation Count** : `text.count('!')`
2. **Question Mark Count** : `text.count('?')`
3. **Uppercase Ratio** : `sum(1 for c in text if c.isupper()) / len(text)`
4. **Has Numbers** : `1 if re.search(r'\\d', text) else 0`
5. **All Caps Words** : Nombre de mots enti√®rement en majuscules

**Approches multiples:**
- **M√©thode 1 (Simple):** Analyse caract√®re par caract√®re
- **M√©thode 2 (Regex):** Utiliser `re.findall(r'\\b[A-Z]+\\b', text)` pour d√©tecter mots en majuscules

**Livrables attendus:**
- Minimum 3 features clickbait (exclamation, uppercase ratio, numbers)
- Feature composite : `Title_Is_Clickbait` (1 si >= 3 exclamations OU uppercase_ratio > 0.5)

**Conseil:** Les fake news utilisent souvent "SHOCKING!!!" ou "YOU WON'T BELIEVE!!!"
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.4: Ratio Partages/Longueur (Bot Detection Proxy)

**Objectif:** Cr√©er une feature pour d√©tecter les partages artificiels.

**Hypoth√®se:** Un article tr√®s court avec √©norm√©ment de partages est suspect (bots).

**Feature √† cr√©er:**
```
Share_Per_Word = Nb_Partages / (Body_Word_Count + 1)
```

**Livrable attendu:** Nouvelle colonne `Share_Per_Word`

**Conseil:** Ajoutez +1 au d√©nominateur pour √©viter division par z√©ro.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### Recipe 4: Math Magic (Transformations)

#### √âtape 2.5: Log Transformation des Partages

**Objectif:** Normaliser la distribution de `Nb_Partages`.

**Approches:**
1. **Log naturel** : `np.log1p(x)` (log(x+1) pour g√©rer les 0)
2. **Square Root** : `np.sqrt(x)` (alternative plus douce)

**Livrable attendu:** Colonne `Nb_Partages_Log`

**Conseil:** La transformation log r√©duit l'impact des valeurs extr√™mes (1M partages).
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.6: Bucketization (Cat√©gorisation des Partages)

**Objectif:** Cr√©er des buckets de viralit√©.

**Cat√©gories sugg√©r√©es:**
- 'Viral' : > 10,000 partages
- 'Popular' : 1,000 - 10,000
- 'Low' : < 1,000

**Approche:** Fonction conditionnelle ou `pd.cut()`

**Livrable attendu:** Colonne `Share_Bucket` (optionnel: encoder en 0/1/2)

**Conseil:** Cette feature peut √™tre utilis√©e pour une analyse secondaire (pas pour le mod√®le principal).
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Final Prep (5 min)

### √âtape 2.7: Encodage de la Cible

**Objectif:** Transformer `Etiquette` (Real/Fake) en valeurs num√©riques (0/1).

**Approches:**
1. **Lambda:** `df['Etiquette'].apply(lambda x: 1 if x == 'Fake' else 0)`
2. **LabelEncoder:** `from sklearn.preprocessing import LabelEncoder`

**Livrable attendu:** Colonne `Etiquette_Encoded` avec 0=Real, 1=Fake

**Conseil:** Toujours v√©rifier la distribution apr√®s encodage (`value_counts()`).
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 2.8: S√©lection des Features

**Objectif:** Cr√©er X (features) et y (target) pour le mod√®le.

**Features recommand√©es pour le mod√®le:**
- Toutes les features statistiques (word count, char count, etc.)
- Toutes les features clickbait (exclamation, uppercase, etc.)
- `Nb_Partages_Log`
- (Optionnel) `Share_Per_Word`

**√Ä EXCLURE:**
- Colonnes textuelles originales (`Title`, `Corps_Texte`, `URL_Source`)
- `ID_Article`
- `Etiquette` (original, non encod√©e)
- `Nb_Partages` (utiliser la version log)

**Livrables attendus:**
- `X` : DataFrame avec features num√©riques uniquement
- `y` : Series avec `Etiquette_Encoded`
- V√©rification : `X.shape` et `y.shape`

**Conseil:** Cr√©ez une liste `feature_columns` puis faites `X = df[feature_columns]`.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    # --- SESSION 3 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 3 : Building & Trusting Your Model (45 min)

## Part 1: The Split (10 min)

### √âtape 3.1: Train/Test Split

**Objectif:** Diviser les donn√©es pour entra√Ænement et √©valuation.

**Approches recommand√©es:**
- **Standard:** 80% train, 20% test
- **Avec Stratification:** `stratify=y` pour garder la m√™me proportion de classes dans train et test

**Param√®tres cl√©s:**
- `test_size=0.2`
- `random_state=42` (pour reproductibilit√©)
- `stratify=y` (IMPORTANT pour classification)

**Livrables attendus:**
- `X_train, X_test, y_train, y_test`
- Affichage des tailles (nombre de lignes)
- V√©rification de la distribution des classes dans train et test

**Conseil:** Utilisez `y_train.value_counts(normalize=True)` pour v√©rifier les proportions.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: Training (15 min)

### √âtape 3.2: Entra√Ænement du Mod√®le

**Objectif:** Entra√Æner un classificateur pour d√©tecter les fake news.

**Mod√®les recommand√©s:**
1. **RandomForestClassifier** ‚úÖ Recommand√©
   - Robuste, g√®re bien les features multiples
   - Param√®tres : `n_estimators=100`, `random_state=42`
   - Avantage : Peut fournir l'importance des features

2. **LogisticRegression** (Alternative)
   - Plus rapide, interpr√©table
   - Bon pour baseline

3. **GradientBoostingClassifier** (Avanc√©)
   - Meilleure performance potentielle
   - Plus lent √† entra√Æner

**Livrables attendus:**
- Mod√®le entra√Æn√© et sauvegard√© dans une variable `model`
- Message de confirmation d'entra√Ænement

**Conseil:** RandomForest avec 100 arbres est un bon √©quilibre performance/vitesse.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Evaluation (20 min)

### Contexte M√©tier

**Type de probl√®me:** Classification binaire √©quilibr√©e (~60% Real, ~40% Fake)

**M√©triques prioritaires:**
1. **F1-Score** ‚Üê PRIORIT√â (√©quilibre pr√©cision/rappel)
2. **Accuracy** (acceptable car classes relativement √©quilibr√©es)
3. **Confusion Matrix** (pour comprendre les types d'erreurs)

**Pourquoi F1 > Accuracy ?**
- Bloquer une vraie news (Faux Positif) = Censure
- Laisser passer une fake news (Faux N√©gatif) = D√©sinformation
- Les deux erreurs sont graves ‚Üí F1 √©quilibre les deux

### √âtape 3.3: Calcul des M√©triques

**Objectif:** √âvaluer la performance du mod√®le.

**M√©triques √† calculer:**
- `accuracy_score(y_test, y_pred)`
- `f1_score(y_test, y_pred)` ‚Üê **PRIORIT√â**
- `classification_report(y_test, y_pred, target_names=['Real', 'Fake'])`

**Livrables attendus:**
- Accuracy (pourcentage)
- F1-Score (0.0 √† 1.0)
- Rapport complet (Precision, Recall, F1 par classe)

**Conseil:** Un F1-Score > 0.75 est bon, > 0.85 est excellent pour ce type de probl√®me.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 3.4: Matrice de Confusion

**Objectif:** Visualiser les types d'erreurs du mod√®le.

**Interpr√©tation:**
```
                Pr√©dit Real    Pr√©dit Fake
Vrai Real       [TN]           [FP] ‚Üê Censure (bad)
Vrai Fake       [FN] ‚Üê D√©sinformation (bad)  [TP]
```

**Approche:**
- Calculer avec `confusion_matrix(y_test, y_pred)`
- Visualiser avec `sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')`

**Livrables attendus:**
- Graphique de la matrice
- Interpr√©tation : Nombre de FP et FN

**Conseil:** Ajoutez les labels `xticklabels` et `yticklabels` pour clarifier.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 3.5: Feature Importance

**Objectif:** Identifier quelles features aident le plus √† d√©tecter les fake news.

**Approche (pour RandomForest):**
```python
feature_importance = pd.DataFrame({
    'Feature': feature_columns,
    'Importance': model.feature_importances_
}).sort_values('Importance', ascending=False)
```

**Livrables attendus:**
- Dataframe tri√© par importance
- Barplot horizontal (`sns.barplot`)
- **Insight:** Quelle est la feature la plus importante ?

**Conseil:** Si `Nb_Partages_Log` domine, essayez de retirer cette feature et r√©-entra√Æner pour voir l'impact du texte seul.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    # --- PART 4 BONUS ---
    cells.append(nbf.v4.new_markdown_cell("""
## üéÅ Part 4: Going Further (Bonus - 15-30 mins)

### Bonus Task 1: Extraction des Mots-Cl√©s de Fake News

**Goal:** Identifier les mots les plus fr√©quents dans les titres de fake news.

**Why it matters:** Comprendre le vocabulaire utilis√© permet de cr√©er des r√®gles de filtrage automatiques.

**Approche:**
1. Filtrer les articles o√π `Etiquette == 'Fake'`
2. Concat√©ner tous les titres en un seul texte
3. Convertir en minuscules et splitter par espaces
4. Utiliser `collections.Counter` pour compter les mots
5. (Optionnel) Retirer les stop words ("the", "a", "is")

**Livrables attendus:**
- Top 10 des mots dans les fake news
- (Bonus) Comparaison avec top 10 des real news

**Conseil:** La librairie `nltk` offre une liste de stop words en anglais : `nltk.corpus.stopwords.words('english')`.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: D√©tection de Patterns Bot-like

**Goal:** Identifier les articles avec un ratio partages/longueur anormalement √©lev√©.

**Why it matters:** Les bots partagent massivement sans lire le contenu. Un article court avec √©norm√©ment de partages est suspect.

**Approche:**
1. Utiliser la feature `Share_Per_Word` cr√©√©e en Session 2
2. Calculer le 95e percentile : `df['Share_Per_Word'].quantile(0.95)`
3. Marquer les articles au-dessus de ce seuil comme "Bot-like"
4. Analyser la distribution Real/Fake dans ce groupe

**Livrables attendus:**
- Seuil calcul√©
- Nombre d'articles suspects
- Crosstab : Bot-like √ó Etiquette
- **Insight:** Les fake news sont-elles plus souvent bot-like ?

**Conseil:** Cr√©ez une colonne binaire `Is_Bot_Like` pour faciliter l'analyse.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 3: Pr√©diction de Viralit√© (R√©gression)

**Goal:** Construire un mod√®le pour pr√©dire le nombre de partages d'un article.

**Why it matters:** Comprendre ce qui rend un contenu viral aide les cr√©ateurs de contenu l√©gitime √† maximiser leur impact.

**Approche:**
1. Changer la cible : `y_viral = df['Nb_Partages_Log']`
2. Features : Toutes sauf `Nb_Partages` et `Nb_Partages_Log`
3. Mod√®le : `RandomForestRegressor`
4. M√©triques : MAE, RMSE, R¬≤

**Livrables attendus:**
- Mod√®le de r√©gression entra√Æn√©
- MAE et R¬≤ Score
- (Bonus) Scatter plot des pr√©dictions vs valeurs r√©elles

**Conseil:** Un R¬≤ > 0.5 serait d√©j√† bon pour ce type de pr√©diction (comportement viral impr√©visible).
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 4: Topic Clustering (Regroupement par Sujet)

**Goal:** Grouper automatiquement les articles en cat√©gories th√©matiques (ex: Politique, Sant√©, C√©l√©brit√©s).

**Why it matters:** Les fake news se concentrent souvent sur des sujets sensibles (sant√©, politique). Identifier les topics permet une analyse cibl√©e.

**Approche (Avanc√©e):**
1. **Vectorisation TF-IDF:**
   - `from sklearn.feature_extraction.text import TfidfVectorizer`
   - `vectorizer = TfidfVectorizer(max_features=50, stop_words='english')`
   - `X_tfidf = vectorizer.fit_transform(df['Title'])`

2. **Clustering KMeans:**
   - `from sklearn.cluster import KMeans`
   - `kmeans = KMeans(n_clusters=3, random_state=42)`
   - `df['Topic_Cluster'] = kmeans.fit_predict(X_tfidf)`

3. **Analyse:**
   - Afficher quelques exemples de titres par cluster
   - Croiser avec `Etiquette` pour voir si certains topics sont plus fake

**Livrables attendus:**
- 3-5 clusters cr√©√©s
- Exemples de titres par cluster
- Distribution Fake/Real par cluster
- **Interpr√©tation:** Nommer les clusters (ex: "Cluster 0 = Politique")

**Conseil:** Commencez avec 3 clusters, puis augmentez si n√©cessaire. Analysez les top mots de chaque cluster avec `vectorizer.get_feature_names_out()`.
"""))

    cells.append(nbf.v4.new_code_cell("# Votre code ici"))

    # Assign cells to notebook
    nb['cells'] = cells

    # Sauvegarde
    with open('Projet_06_Intermediaire.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    print("‚úÖ Notebook Interm√©diaire g√©n√©r√© : Projet_06_Intermediaire.ipynb")

if __name__ == "__main__":
    generer_notebook_intermediaire()
