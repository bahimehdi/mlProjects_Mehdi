import nbformat as nbf

def generer_notebook_debutant():
    nb = nbf.v4.new_notebook()
    
    cells = []
    
    # --- Titre et Introduction ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸŽ“ Projet 4 : SystÃ¨me d'Alerte PrÃ©coce de DÃ©crochage Scolaire
## Version DÃ©butant - "Je te montre, puis tu rÃ©pÃ¨tes"

---

### ðŸŽ¯ L'Objectif de ce Projet

Le dÃ©crochage scolaire a des consÃ©quences graves pour les Ã©lÃ¨ves et les Ã©coles. Votre mission est de **dÃ©tecter les Ã©lÃ¨ves Ã  risque** (`A_Decroche = 1`) afin de pouvoir intervenir avant qu'il ne soit trop tard.

**Ce que vous allez apprendre :**
- ðŸ“Š Analyser des donnÃ©es Ã©ducatives (notes, prÃ©sence, trajet)
- âš–ï¸ GÃ©rer un problÃ¨me de **Classification DÃ©sÃ©quilibrÃ©e** (peu de dÃ©crocheurs, mais importants Ã  trouver)
- ðŸ¤– Utiliser `RandomForestClassifier` avec `class_weight='balanced'`
- ðŸŽ¯ Optimiser le **Rappel (Recall)** pour ne manquer aucun Ã©lÃ¨ve en difficultÃ©

---

> **ðŸ’¡ Comment utiliser ce notebook :**
> 1. **Les cellules avec du code complet** â†’ Lisez et exÃ©cutez-les pour voir l'exemple
> 2. **Les cellules avec # TODO** â†’ C'est votre tour ! RÃ©pÃ©tez la technique
> 3. **Les Questions â“** â†’ RÃ©flÃ©chissez avant de passer Ã  la suite

---
"""))

    # --- SESSION 1 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ“‹ SESSION 1 : From Raw Data to Clean Insights (45 min)

## Part 1: The Setup (10 min)

### ðŸ“˜ Theory: Les BibliothÃ¨ques
"""))

    cells.append(nbf.v4.new_code_cell("""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12
sns.set_style("whitegrid")

print("âœ… BibliothÃ¨ques importÃ©es !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã‰tape 1.1 : Charger les DonnÃ©es
Le fichier est `decrochage_scolaire.csv`.
"""))

    cells.append(nbf.v4.new_code_cell("""
df = pd.read_csv('decrochage_scolaire.csv')

print("ðŸ“Š AperÃ§u des donnÃ©es :")
display(df.head())
print(f"\\nâœ… Dimensions : {df.shape[0]} Ã©lÃ¨ves, {df.shape[1]} colonnes")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: The Sanity Check (15 min)

### ðŸ“˜ Theory: Valeurs Manquantes
VÃ©rifions si nous avons des trous dans nos donnÃ©es.
"""))

    cells.append(nbf.v4.new_code_cell("""
print("ðŸ” Valeurs manquantes :")
print(df.isnull().sum())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Exemple : Remplir 'Temps_Trajet'
Pour le temps de trajet (numÃ©rique), nous allons utiliser la **mÃ©diane**.
"""))

    cells.append(nbf.v4.new_code_cell("""
mediane_trajet = df['Temps_Trajet'].median()
df['Temps_Trajet'].fillna(mediane_trajet, inplace=True)
print(f"âœ… Temps_Trajet rempli avec : {mediane_trajet}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
Remplissez les valeurs manquantes de `Education_Parents` (catÃ©gorique) avec le **mode** (la valeur la plus frÃ©quente).
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Remplir Education_Parents avec le mode

# mode_edu = df['Education_Parents'].mode()[0]
# df['Education_Parents'].fillna(mode_edu, inplace=True)
# print(f"âœ… Education_Parents rempli avec : {mode_edu}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Exploratory Data Analysis (20 min)

### ðŸ“Š Visualisation 1 : Le DÃ©sÃ©quilibre de Classe
C'est CRITIQUE. Combien d'Ã©lÃ¨ves ont dÃ©crochÃ© vs sont restÃ©s ?
"""))

    cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='A_Decroche', palette=['green', 'red'])
plt.title('Distribution des DÃ©crochages (0=Non, 1=Oui)')
plt.show()

print("Pourcentages :")
print(df['A_Decroche'].value_counts(normalize=True) * 100)
"""))

    cells.append(nbf.v4.new_markdown_cell("""
> **âš ï¸ Warning:** Vous voyez ce dÃ©sÃ©quilibre ? Il y a beaucoup moins de dÃ©crocheurs. Si notre modÃ¨le dit "Personne ne dÃ©croche", il aura raison 90% du temps (Accuracy), mais il sera INUTILE ! Nous devrons utiliser le **Recall** comme mÃ©trique.
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
Visualisez l'impact de la `Presence` sur le dÃ©crochage avec un **Boxplot**.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Boxplot Presence vs A_Decroche

# plt.figure(figsize=(8, 5))
# sns.boxplot(data=df, x='A_Decroche', y='Presence', palette=['green', 'red'])
# plt.title('Impact de la PrÃ©sence sur le DÃ©crochage')
# plt.show()
"""))

    # --- SESSION 2 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ“‹ SESSION 2 : The Art of Feature Engineering (45 min)

## Part 1: The Concept (10 min)
Transformons nos donnÃ©es brutes en indicateurs de risque.

## Part 2: The Lab - Choose Your Recipe (30 min)

### ðŸ·ï¸ Recipe 2: Categories
`Education_Parents` est du texte. Transformons-le en nombres avec **One-Hot Encoding**.
"""))

    cells.append(nbf.v4.new_code_cell("""
df = pd.get_dummies(df, columns=['Education_Parents'], prefix='Edu')
print("âœ… Encodage terminÃ© !")
display(df.head())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### âž— Recipe 4: Math Magic
CrÃ©ons un **Score de Risque** simple basÃ© sur notre intuition.
Faible PrÃ©sence + Faibles Notes = Danger.
"""))

    cells.append(nbf.v4.new_code_cell("""
# Exemple : Score inversÃ© (plus c'est haut, plus c'est risquÃ©)
# On normalise grossiÃ¨rement : (100 - Presence) + (20 - Notes)*5
df['Risk_Score'] = (100 - df['Presence']) + (20 - df['Notes_Precedentes']) * 5

print("âœ… Feature Risk_Score crÃ©Ã©e !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
CatÃ©gorisez le `Temps_Trajet` en 'Court', 'Moyen', 'Long' (Binning).
- 0-15 min = Court
- 15-45 min = Moyen
- 45+ min = Long
Puis encodez-le (ou gardez-le numÃ©rique si vous prÃ©fÃ©rez, mais essayons le binning pour l'exercice).
Pour simplifier ici, crÃ©ons juste une feature binaire `Trajet_Long` (> 45 min).
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: CrÃ©er Trajet_Long

# df['Trajet_Long'] = (df['Temps_Trajet'] > 45).astype(int)
# print("âœ… Feature Trajet_Long crÃ©Ã©e !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Final Prep (5 min)
PrÃ©parons X et y.
"""))

    cells.append(nbf.v4.new_code_cell("""
# Supprimer l'ID (inutile)
if 'ID_Etudiant' in df.columns:
    df = df.drop(columns=['ID_Etudiant'])

X = df.drop(columns=['A_Decroche'])
y = df['A_Decroche']

print(f"âœ… PrÃªt ! X shape: {X.shape}, y shape: {y.shape}")
"""))

    # --- SESSION 3 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ“‹ SESSION 3 : Building & Trusting Your Model (45 min)

## Part 1: The Split (10 min)
**IMPORTANT :** Comme nous avons peu de dÃ©crocheurs, nous devons utiliser `stratify=y` pour Ãªtre sÃ»r d'en avoir dans le Train ET dans le Test.
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("âœ… Split stratifiÃ© effectuÃ© !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: Training (15 min)

### ðŸš¨ Gestion du DÃ©sÃ©quilibre
Nous allons utiliser `class_weight='balanced'`. Cela dit au modÃ¨le : "Attention, chaque erreur sur un dÃ©crocheur compte DOUBLE (ou plus) !"
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.ensemble import RandomForestClassifier

# ModÃ¨le avec poids Ã©quilibrÃ©s
model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)

print("ðŸš€ EntraÃ®nement...")
model.fit(X_train, y_train)
print("âœ… ModÃ¨le entraÃ®nÃ© !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Evaluation (20 min)

### ðŸŽ¯ Focus sur le RECALL (Rappel)
- **Recall** = CapacitÃ© Ã  trouver TOUS les dÃ©crocheurs.
- Si on rate un Ã©lÃ¨ve Ã  risque (Faux NÃ©gatif), c'est grave.
- Si on alerte pour rien (Faux Positif), on perd juste un peu de temps de conseiller.
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.metrics import classification_report, confusion_matrix, recall_score

y_pred = model.predict(X_test)

# MÃ©triques
recall = recall_score(y_test, y_pred)
print(f"ðŸŽ¯ RECALL (DÃ©crocheurs) : {recall:.2%}")
print("\\nðŸ“Š Rapport complet :")
print(classification_report(y_test, y_pred))
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
Affichez la **Matrice de Confusion** pour voir combien de Faux NÃ©gatifs nous avons.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Matrice de Confusion

# cm = confusion_matrix(y_test, y_pred)
# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
# plt.xlabel('PrÃ©dit')
# plt.ylabel('RÃ©el')
# plt.title('Matrice de Confusion')
# plt.show()
"""))

    # --- PART 4 BONUS ---
    cells.append(nbf.v4.new_markdown_cell("""
## ðŸŽ Part 4: Going Further (Bonus - 15-30 mins)

### Bonus Task 1: Les Facteurs de Risque
**Goal:** Qu'est-ce qui cause le dÃ©crochage ? (Feature Importance)
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Plot Feature Importance
# importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
# importances.plot(kind='bar', color='teal')
# plt.title('Facteurs de Risque Principaux')
# plt.show()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: Segmentation des Ã‰lÃ¨ves
**Goal:** Grouper les Ã©lÃ¨ves par profil (ex: "Bons mais loin", "En difficultÃ© partout").
Utilisez KMeans sur `Presence` et `Notes_Precedentes`.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: KMeans Clustering
# from sklearn.cluster import KMeans
# kmeans = KMeans(n_clusters=3, random_state=42)
# df['Cluster'] = kmeans.fit_predict(df[['Presence', 'Notes_Precedentes']])
# sns.scatterplot(data=df, x='Presence', y='Notes_Precedentes', hue='Cluster', palette='viridis')
# plt.show()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 3: Recommandation d'Intervention
**Goal:** CrÃ©er une rÃ¨gle simple.
Si `Risk_Score` > X, recommander "Entretien Conseiller".
Si `Trajet_Long` == 1, recommander "Aide Transport".
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Logique de recommandation
# def recommend(row):
#     actions = []
#     if row['Risk_Score'] > 80: actions.append("Entretien PÃ©dagogique")
#     if row['Trajet_Long'] == 1: actions.append("Pass Bus")
#     return ", ".join(actions) if actions else "Aucune"

# df['Intervention'] = df.apply(recommend, axis=1)
# display(df[['Risk_Score', 'Trajet_Long', 'Intervention']].head(10))
"""))

    nb['cells'] = cells
    nbf.write(nb, 'donnees_fr/Projet_04/Projet_04_Debutant.ipynb')

if __name__ == "__main__":
    generer_notebook_debutant()
