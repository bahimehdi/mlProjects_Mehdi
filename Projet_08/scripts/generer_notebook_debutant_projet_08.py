import nbformat as nbf

def generer_notebook_debutant():
    nb = nbf.v4.new_notebook()
    
    cells = []
    
    # --- Titre et Introduction ---
    cells.append(nbf.v4.new_markdown_cell("""
# üéì Projet 8 : Analyse de Sentiment en Sant√© Mentale
## Version D√©butant - "Je te montre, puis tu r√©p√®tes"

---

### üéØ L'Objectif de ce Projet

Les r√©seaux sociaux peuvent r√©v√©ler des signes de d√©pression ou d'anxi√©t√©. Votre mission est de **d√©tecter l'√©tat mental** √† partir de posts textuels (`Normal`, `Depressed`, `Anxious`) afin de pouvoir intervenir et proposer du soutien.

**Ce que vous allez apprendre :**
- üìù Analyser des **donn√©es textuelles** (NLP - Natural Language Processing)
- üïê Extraire des features temporelles (heure, weekend, etc.)
- üî§ Cr√©er des features NLP (longueur, sentiment, mots n√©gatifs)
- ü§ñ Utiliser `RandomForestClassifier` pour la **classification multi-classe**
- üìä Comparer les performances sur 3 cat√©gories avec **F1-Score**

---

> **üí° Comment utiliser ce notebook :**
> 1. **Les cellules avec du code complet** ‚Üí Lisez et ex√©cutez-les pour voir l'exemple
> 2. **Les cellules avec # TODO** ‚Üí C'est votre tour ! R√©p√©tez la technique
> 3. **Les Questions ‚ùì** ‚Üí R√©fl√©chissez avant de passer √† la suite

---
"""))
    
    # --- SESSION 1 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 1 : From Raw Data to Clean Insights (45 min)

## Part 1: The Setup (10 min)

### üìò Theory: Les Biblioth√®ques

Nous allons utiliser des outils sp√©cialement con√ßus pour le **texte** (NLTK, TextBlob).
"""))
    
    cells.append(nbf.v4.new_code_cell("""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Configuration
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

# NLP Libraries (on va les installer si elles manquent)
try:
    from textblob import TextBlob
    print("‚úÖ TextBlob disponible")
except:
    print("‚ö†Ô∏è TextBlob manquant. Installez avec: pip install textblob")

print("‚úÖ Biblioth√®ques import√©es !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √âtape 1.1 : Charger les Donn√©es
Le fichier est `sante_mentale.csv`.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
df = pd.read_csv('sante_mentale.csv')

print("üìä Aper√ßu des donn√©es :")
display(df.head())
print(f"\\n‚úÖ Dimensions : {df.shape[0]} posts, {df.shape[1]} colonnes")
print(f"\\n‚ÑπÔ∏è Colonnes : {df.columns.tolist()}")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
> **üí° Tip:** Notez la colonne `Texte` - c'est l√† que se trouve l'information principale ! 
> `Horodatage` nous permettra d'extraire l'heure, et `Plateforme` est cat√©gorique.
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: The Sanity Check (15 min)

### üìò Theory: Valeurs Manquantes
V√©rifions si nous avons des trous dans nos donn√©es.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
print("üîç Valeurs manquantes :")
print(df.isnull().sum())
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è Exemple : Remplir 'Texte'
Pour le texte manquant, nous allons utiliser un texte neutre par d√©faut.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
df['Texte'].fillna("No text", inplace=True)
print("‚úÖ Texte manquant rempli avec : 'No text'")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è V√©rification des Duplicates
"""))
    
    cells.append(nbf.v4.new_code_cell("""
print(f"üîç Duplicates trouv√©s : {df.duplicated().sum()}")
if df.duplicated().sum() > 0:
    df = df.drop_duplicates()
    print("‚úÖ Duplicates supprim√©s !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Exploratory Data Analysis (20 min)

### üìä Visualisation 1 : Distribution des √âtiquettes
Combien de posts sont `Normal`, `Depressed`, `Anxious` ?
"""))
    
    cells.append(nbf.v4.new_code_cell("""
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
etiquette_counts = df['Etiquette'].value_counts()
colors = ['green', 'orange', 'red']
etiquette_counts.plot(kind='bar', color=colors)
plt.title('Distribution des √âtiquettes de Sant√© Mentale')
plt.xlabel('√âtiquette')
plt.ylabel('Nombre de Posts')
plt.xticks(rotation=0)
plt.show()

print("\\nPourcentages :")
print(df['Etiquette'].value_counts(normalize=True) * 100)
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
> **‚ö†Ô∏è Warning:** La classe `Normal` est l√©g√®rement majoritaire (~50%), mais les classes `Depressed` et `Anxious` sont importantes √† d√©tecter !
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √Ä vous de jouer !
Visualisez la r√©partition des posts par **Plateforme** avec un graphique en barres.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Graphique en barres pour Plateforme

# plt.figure(figsize=(8, 5))
# df['Plateforme'].value_counts().plot(kind='bar', color='skyblue')
# plt.title('R√©partition des Posts par Plateforme')
# plt.xlabel('Plateforme')
# plt.ylabel('Nombre de Posts')
# plt.xticks(rotation=0)
# plt.show()
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### ‚ùì Question de R√©flexion
Quelle plateforme a le plus de posts ? Cela pourrait-il influencer notre mod√®le ?
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üìä Visualisation 2 : Longueur du Texte par √âtiquette
Les posts d√©prim√©s ou anxieux sont-ils plus courts/longs ?
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# Cr√©er une feature temporaire pour la longueur
df['Text_Length_Temp'] = df['Texte'].str.len()

plt.figure(figsize=(10, 5))
for etiquette in df['Etiquette'].unique():
    subset = df[df['Etiquette'] == etiquette]['Text_Length_Temp']
    plt.hist(subset, alpha=0.5, label=etiquette, bins=20)

plt.title('Distribution de la Longueur du Texte par √âtiquette')
plt.xlabel('Longueur du Texte (caract√®res)')
plt.ylabel('Fr√©quence')
plt.legend()
plt.show()

df = df.drop(columns=['Text_Length_Temp'])  # Nettoyage
"""))
    
    # --- SESSION 2 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 2 : The Art of Feature Engineering (45 min)

## Part 1: The Concept (10 min)

### üß† Qu'est-ce que le Feature Engineering ?

**Analogie :** Imaginez que vous √™tes un d√©tective psychologue. Un texte brut, c'est comme une conversation enregistr√©e. Vous devez extraire des **indices** :
- üìè Combien de mots utilisent-ils ? (Longueur)
- üò° Y a-t-il des mots n√©gatifs ? (Sentiment)
- üïê √Ä quelle heure ont-ils post√© ? (Contexte temporel)

C'est exactement ce que nous allons faire avec le **NLP (Natural Language Processing)**.

---

## Part 2: The Lab - Choose Your Recipe (30 min)

### üìù Recipe 3: Text & NLP (PRIMARY)

#### üìò Theory: Features Textuelles de Base

Commen√ßons simple :
- **Text_Length** : Nombre de caract√®res
- **Word_Count** : Nombre de mots
- **Avg_Word_Length** : Longueur moyenne des mots
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# Exemple complet pour Text_Length
df['Text_Length'] = df['Texte'].str.len()
print("‚úÖ Feature Text_Length cr√©√©e !")
print(df[['Texte', 'Text_Length']].head(3))
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √Ä vous de jouer !
Cr√©ez la feature **Word_Count** (nombre de mots dans `Texte`).

**Astuce :** Utilisez `.str.split().str.len()`
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Cr√©er Word_Count

# df['Word_Count'] = df['Texte'].str.split().str.len()
# print("‚úÖ Feature Word_Count cr√©√©e !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### üìò Theory: Analyse de Sentiment avec TextBlob

**TextBlob** peut analyser le **sentiment** (positif/n√©gatif) et la **subjectivit√©** (opinion vs fait).

- **Polarity** : -1 (tr√®s n√©gatif) ‚Üí +1 (tr√®s positif)
- **Subjectivity** : 0 (objectif) ‚Üí 1 (subjectif)
"""))
    
    cells.append(nbf.v4.new_code_cell("""
from textblob import TextBlob

# Exemple pour Sentiment_Polarity
def get_polarity(text):
    try:
        return TextBlob(str(text)).sentiment.polarity
    except:
        return 0

df['Sentiment_Polarity'] = df['Texte'].apply(get_polarity)
print("‚úÖ Feature Sentiment_Polarity cr√©√©e !")
print(df[['Texte', 'Sentiment_Polarity']].head(3))
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √Ä vous de jouer !
Cr√©ez **Sentiment_Subjectivity** en adaptant la fonction ci-dessus.

**Astuce :** Remplacez `.sentiment.polarity` par `.sentiment.subjectivity`
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Cr√©er Sentiment_Subjectivity

# def get_subjectivity(text):
#     try:
#         return TextBlob(str(text)).sentiment.subjectivity
#     except:
#         return 0

# df['Sentiment_Subjectivity'] = df['Texte'].apply(get_subjectivity)
# print("‚úÖ Feature Sentiment_Subjectivity cr√©√©e !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### üéØ Recipe 6: Domain-Specific Features (Mental Health)

**Contexte M√©tier :** Pour la sant√© mentale, certains mots sont des **indicateurs forts** :
- Mots n√©gatifs : "sad", "alone", "hopeless", "tired"
- Mots urgents : "suicide", "hurt myself", "end it"
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# Liste de mots n√©gatifs
negative_words = ['sad', 'alone', 'hopeless', 'tired', 'depressed', 'anxious', 'worry', 'fear', 'bad', 'awful']

# Compter les mots n√©gatifs
def count_negative_words(text):
    text_lower = str(text).lower()
    return sum([1 for word in negative_words if word in text_lower])

df['Negative_Word_Count'] = df['Texte'].apply(count_negative_words)
df['Has_Negative_Words'] = (df['Negative_Word_Count'] > 0).astype(int)

print("‚úÖ Features Negative_Word_Count et Has_Negative_Words cr√©√©es !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √Ä vous de jouer !
Cr√©ez une feature **Has_Urgent_Keywords** pour d√©tecter les mots li√©s aux id√©es suicidaires.

**Liste sugg√©r√©e :** `['suicide', 'kill', 'die', 'death', 'end it', 'hurt myself']`
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Cr√©er Has_Urgent_Keywords

# urgent_words = ['suicide', 'kill', 'die', 'death', 'end it', 'hurt myself']
# def has_urgent(text):
#     text_lower = str(text).lower()
#     return int(any(word in text_lower for word in urgent_words))

# df['Has_Urgent_Keywords'] = df['Texte'].apply(has_urgent)
# print("‚úÖ Feature Has_Urgent_Keywords cr√©√©e !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üïê Recipe 1: Dates & Time

#### üìò Theory: Extraction de Features Temporelles

L'heure du post peut indiquer l'√©tat mental (posts nocturnes, weekends, etc.).
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# Convertir Horodatage en datetime
df['Horodatage'] = pd.to_datetime(df['Horodatage'])

# Extraire Hour
df['Hour'] = df['Horodatage'].dt.hour
print("‚úÖ Feature Hour cr√©√©e !")
print(df[['Horodatage', 'Hour']].head(3))
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √Ä vous de jouer !
Cr√©ez les features suivantes :
1. **Is_Weekend** : 1 si samedi/dimanche, 0 sinon (DayOfWeek >= 5)
2. **Is_Night** : 1 si entre 22h et 6h, 0 sinon
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Cr√©er Is_Weekend et Is_Night

# df['DayOfWeek'] = df['Horodatage'].dt.dayofweek
# df['Is_Weekend'] = (df['DayOfWeek'] >= 5).astype(int)

# df['Is_Night'] = ((df['Hour'] >= 22) | (df['Hour'] <= 6)).astype(int)
# print("‚úÖ Features Is_Weekend et Is_Night cr√©√©es !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üè∑Ô∏è Recipe 2: Categories

Encodons la **Plateforme** avec One-Hot Encoding.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
df = pd.get_dummies(df, columns=['Plateforme'], prefix='Platform')
print("‚úÖ Encodage de Plateforme termin√© !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Final Prep (5 min)

### üßπ Nettoyage Final
Supprimons les colonnes inutiles.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# Supprimer les colonnes non n√©cessaires
columns_to_drop = ['ID_Post', 'Texte', 'Horodatage']
# Optionnel : garder DayOfWeek ou le supprimer si d√©j√† transform√©
if 'DayOfWeek' in df.columns:
    columns_to_drop.append('DayOfWeek')

df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])

print(f"‚úÖ Colonnes restantes : {df.columns.tolist()}")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üéØ Pr√©parer X et y
"""))
    
    cells.append(nbf.v4.new_code_cell("""
X = df.drop(columns=['Etiquette'])
y = df['Etiquette']

print(f"‚úÖ Pr√™t ! X shape: {X.shape}, y shape: {y.shape}")
print(f"Features : {X.columns.tolist()}")
"""))
    
    # --- SESSION 3 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 3 : Building & Trusting Your Model (45 min)

## Part 1: The Split (10 min)

Pour la classification multi-classe, nous utilisons `stratify=y` pour garder les proportions.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("‚úÖ Split stratifi√© effectu√© !")
print(f"Train : {X_train.shape}, Test : {X_test.shape}")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: Training (15 min)

### ü§ñ RandomForestClassifier pour Multi-Classe
Pas besoin de modification sp√©ciale. RandomForest g√®re automatiquement les 3 classes.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)

print("üöÄ Entra√Ænement...")
model.fit(X_train, y_train)
print("‚úÖ Mod√®le entra√Æn√© !")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Evaluation (20 min)

### üìä M√©triques pour Multi-Classe

- **Accuracy** : Pourcentage global de pr√©dictions correctes
- **F1-Score** : Moyenne harmonique de Pr√©cision et Recall (par classe)
- **Confusion Matrix** : Voir o√π le mod√®le se trompe
"""))
    
    cells.append(nbf.v4.new_code_cell("""
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"üéØ ACCURACY : {accuracy:.2%}")
print("\\nüìä Rapport complet (par classe) :")
print(classification_report(y_test, y_pred))
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
> **üí° Tip:** Regardez le **F1-Score** pour `Depressed` et `Anxious`. Ce sont les classes les plus importantes √† d√©tecter !
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### üõ†Ô∏è √Ä vous de jouer !
Affichez la **Matrice de Confusion** pour voir les erreurs de classification.
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Matrice de Confusion

# import matplotlib.pyplot as plt
# cm = confusion_matrix(y_test, y_pred, labels=['Normal', 'Depressed', 'Anxious'])
# plt.figure(figsize=(8, 6))
# plt.imshow(cm, cmap='Blues', interpolation='nearest')
# plt.colorbar()
# plt.title('Matrice de Confusion')
# plt.xlabel('Pr√©dit')
# plt.ylabel('R√©el')
# tick_marks = range(3)
# plt.xticks(tick_marks, ['Normal', 'Depressed', 'Anxious'])
# plt.yticks(tick_marks, ['Normal', 'Depressed', 'Anxious'])
# for i in range(3):
#     for j in range(3):
#         plt.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')
# plt.show()
"""))
    
    # --- PART 4 BONUS ---
    cells.append(nbf.v4.new_markdown_cell("""
## üéÅ Part 4: Going Further (Bonus - 15-30 mins)

The main model is trained! Now let's tackle the optional challenges from the project brief.

### Bonus Task 1: Analyser les Tendances d'Humeur par Moment de la Journ√©e

**Goal:** Voir si certaines heures sont associ√©es √† plus de d√©pression ou d'anxi√©t√©.

**Why it matters:** Cela peut aider √† d√©ployer des interventions cibl√©es (ex: chatbot de soutien actif la nuit).

**Approach:**
1. Grouper les posts par `Hour` et `Etiquette`
2. Compter les occurrences
3. Visualiser avec un graphique en lignes ou heatmap
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Tendances par heure
# Recr√©ez la colonne Hour si n√©cessaire √† partir des donn√©es originales
# ou sauvegardez-la avant Session 2

# df_original = pd.read_csv('sante_mentale.csv')
# df_original['Horodatage'] = pd.to_datetime(df_original['Horodatage'])
# df_original['Hour'] = df_original['Horodatage'].dt.hour

# mood_by_hour = df_original.groupby(['Hour', 'Etiquette']).size().unstack(fill_value=0)
# mood_by_hour.plot(kind='line', figsize=(12, 6), marker='o')
# plt.title('Tendances d\\'Humeur par Heure de la Journ√©e')
# plt.xlabel('Heure')
# plt.ylabel('Nombre de Posts')
# plt.legend(title='√âtiquette')
# plt.grid(True)
# plt.show()
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: Identifier les Mots D√©clencheurs pour Chaque Cat√©gorie

**Goal:** Quels mots apparaissent le plus souvent dans les posts `Depressed` vs `Anxious` vs `Normal` ?

**Why it matters:** Comprendre le vocabulaire associ√© √† chaque √©tat mental pour affiner les interventions.

**Approach:**
1. S√©parer le texte par √©tiquette
2. Compter les mots les plus fr√©quents (apr√®s nettoyage : minuscules, stopwords)
3. Afficher les Top 10 mots par cat√©gorie
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Mots d√©clencheurs
# from collections import Counter
# import re

# df_original = pd.read_csv('sante_mentale.csv')

# def get_top_words(df, label, top_n=10):
#     texts = df[df['Etiquette'] == label]['Texte'].dropna()
#     all_words = []
#     for text in texts:
#         words = re.findall(r'\\b[a-z]+\\b', text.lower())  # Mots en minuscules
#         all_words.extend(words)
#     
#     # Retirer les stopwords basiques (optionnel, pour simplifier)
#     stopwords = ['i', 'and', 'the', 'a', 'to', 'is', 'it', 'of', 'in', 'for', 'on', 'with']
#     filtered_words = [w for w in all_words if w not in stopwords and len(w) > 2]
#     
#     return Counter(filtered_words).most_common(top_n)

# for label in ['Normal', 'Depressed', 'Anxious']:
#     print(f"\\nüîë Top 10 mots pour {label}:")
#     print(get_top_words(df_original, label))
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 3: Regrouper les Utilisateurs en Groupes de Soutien

**Goal:** Utiliser le clustering pour identifier des profils similaires (ex: "Anxieux nocturnes", "D√©prim√©s le week-end").

**Why it matters:** Cr√©er des groupes de soutien homog√®nes pour une meilleure entraide.

**Approach:**
1. Utiliser KMeans sur les features `Sentiment_Polarity`, `Negative_Word_Count`, `Is_Night`
2. Cr√©er 3-4 clusters
3. Analyser la composition de chaque cluster
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Clustering KMeans
# from sklearn.cluster import KMeans

# # Cr√©er un dataframe avec les features importantes
# features_for_clustering = df[['Sentiment_Polarity', 'Negative_Word_Count', 'Is_Night']].copy()
# # (Assurez-vous que ces features existent dans df)

# kmeans = KMeans(n_clusters=3, random_state=42)
# df['Support_Group'] = kmeans.fit_predict(features_for_clustering)

# print("‚úÖ Clustering effectu√© !")
# print("\\nDistribution des groupes :")
# print(df['Support_Group'].value_counts())

# # Analyser chaque groupe
# for group in range(3):
#     print(f"\\n--- Groupe {group} ---")
#     subset = df[df['Support_Group'] == group]
#     print(f"Taille : {len(subset)}")
#     print(f"Sentiment moyen : {subset['Sentiment_Polarity'].mean():.2f}")
#     print(f"% de posts nocturnes : {subset['Is_Night'].mean() * 100:.1f}%")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 4: D√©tecter les Cas Urgents

**Goal:** Cr√©er un syst√®me d'alerte pour les posts contenant des mots-cl√©s d'id√©es suicidaires.

**Why it matters:** Priorit√© absolue - sauver des vies en d√©tectant les signaux de danger imm√©diat.

**Approach:**
1. Utiliser la feature `Has_Urgent_Keywords` cr√©√©e pr√©c√©demment
2. Filtrer les posts urgents
3. Afficher un tableau r√©capitulatif avec recommandations
"""))
    
    cells.append(nbf.v4.new_code_cell("""
# TODO: Syst√®me d'alerte urgente
# df_original = pd.read_csv('sante_mentale.csv')

# urgent_words = ['suicide', 'kill', 'die', 'death', 'end it', 'hurt myself']
# def has_urgent(text):
#     text_lower = str(text).lower()
#     return int(any(word in text_lower for word in urgent_words))

# df_original['Has_Urgent_Keywords'] = df_original['Texte'].apply(has_urgent)

# urgent_cases = df_original[df_original['Has_Urgent_Keywords'] == 1]

# print(f"üö® ALERTE : {len(urgent_cases)} cas urgents d√©tect√©s !")
# print("\\nD√©tails des cas urgents :")
# display(urgent_cases[['ID_Post', 'Texte', 'Etiquette', 'Horodatage']])

# print("\\nüìû RECOMMANDATION : Ces posts n√©cessitent une intervention imm√©diate (contact ligne de pr√©vention du suicide).")
"""))
    
    cells.append(nbf.v4.new_markdown_cell("""
---

## üéâ F√©licitations !

Vous avez termin√© le Projet 8 ! Vous savez maintenant :
- ‚úÖ Extraire des features NLP (longueur, sentiment, mots-cl√©s)
- ‚úÖ Analyser des donn√©es temporelles
- ‚úÖ Classifier des √©tats mentaux avec Machine Learning
- ‚úÖ D√©tecter des cas urgents pour sauver des vies

**Next Steps :**
- Testez d'autres mod√®les (Logistic Regression, SVM)
- Ajoutez plus de mots-cl√©s contextuels
- Cr√©ez une interface web pour le syst√®me d'alerte
"""))
    
    nb['cells'] = cells
    nbf.write(nb, 'Projet_08_Debutant.ipynb')
    print("‚úÖ Notebook d√©butant g√©n√©r√© : Projet_08_Debutant.ipynb")

if __name__ == "__main__":
    generer_notebook_debutant()
