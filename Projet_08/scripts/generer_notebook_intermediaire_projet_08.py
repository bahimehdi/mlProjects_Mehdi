import nbformat as nbf

def generer_notebook_intermediaire():
    nb = nbf.v4.new_notebook()
    
    cells = []
    
    # --- Titre ---
    cells.append(nbf.v4.new_markdown_cell("""
# üéì Projet 8 : Analyse de Sentiment en Sant√© Mentale
## Version Interm√©diaire - "Voici le chemin, marche seul"

---

### üéØ L'Objectif
Construire un mod√®le de classification capable de **d√©tecter l'√©tat mental** √† partir de posts sur les r√©seaux sociaux (`Etiquette` : `Normal`, `Depressed`, `Anxious`).

**Contexte M√©tier :**
- **Cible** : `Etiquette` (Multi-classe : Normal, Depressed, Anxious)
- **Probl√®me** : Classification multi-classe avec l√©ger d√©s√©quilibre (50% Normal, 25% chacune pour les autres).
- **Priorit√©** : **F1-Score √©quilibr√©**. Les classes `Depressed` et `Anxious` sont plus importantes √† d√©tecter (impact sur la sant√©).
- **Sp√©cificit√©** : Projet **NLP-heavy** - l'essentiel de l'information est dans le texte.

---

### üìã SESSION 1 : From Raw Data to Clean Insights

#### √âtape 1.1 : Chargement et Inspection
**Objectif :** Charger `sante_mentale.csv` et comprendre la structure.

**Livrables attendus :**
- Dimensions et types.
- Identification de la colonne texte (`Texte`), temporelle (`Horodatage`), et cat√©gorielle (`Plateforme`).
- Distribution des √©tiquettes (check du d√©s√©quilibre).
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 1.2 : Nettoyage & Gestion des Manquants
**Objectif :** Remplir les valeurs manquantes dans `Texte`.

**Approches recommand√©es :**
- `Texte` (Textuel) : Remplacer par un placeholder comme `"No text"` ou `""`.
- V√©rifier et supprimer les duplicates si n√©cessaires.

**Livrables attendus :**
- Dataset propre sans NaN.
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 1.3 : Exploratory Data Analysis (EDA)
**Objectif :** Comprendre les patterns dans les donn√©es.

**Analyses √† r√©aliser :**
1. **Countplot** de `Etiquette` : Quantifier le d√©s√©quilibre.
2. **Barplot** : R√©partition par `Plateforme`.
3. **Distribution de la longueur du texte** : Histogrammes par √©tiquette (les posts d√©prim√©s sont-ils plus courts/longs ?).
4. **WordCloud** (optionnel) : Visualiser les mots les plus fr√©quents par cat√©gorie.

**Question :** Y a-t-il des diff√©rences notables dans le style ou la longueur des textes entre les 3 cat√©gories ?
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
---

### üìã SESSION 2 : The Art of Feature Engineering

#### √âtape 2.1 : Recipe 3 - Text & NLP Features (PRIMARY)
**Objectif :** Extraire des features textuelles riches.

**Features de Base √† cr√©er :**
1. **Text_Length** : Nombre de caract√®res (`str.len()`)
2. **Word_Count** : Nombre de mots (`str.split().str.len()`)
3. **Avg_Word_Length** : Longueur moyenne des mots
4. **Char_Count** : Nombre de caract√®res (alias de Text_Length)

**Features de Sentiment (TextBlob recommand√©) :**
1. **Sentiment_Polarity** : Score de -1 (n√©gatif) √† +1 (positif)
2. **Sentiment_Subjectivity** : Score de 0 (objectif) √† 1 (subjectif)

**Librairie :** `from textblob import TextBlob`

**Conseil :** Cr√©ez des fonctions auxiliaires pour g√©rer les exceptions (texte vide, etc.).
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.2 : Recipe 6 - Domain-Specific Features (Mental Health)
**Objectif :** Cr√©er des indicateurs sp√©cifiques √† la sant√© mentale.

**Features M√©tier √† cr√©er :**

1. **Negative_Word_Count** : Compter les mots n√©gatifs
   - Liste sugg√©r√©e : `['sad', 'alone', 'hopeless', 'tired', 'depressed', 'anxious', 'worry', 'fear', 'bad', 'awful']`
   - Approche : Cr√©er une fonction qui compte les occurrences (case-insensitive)

2. **Has_Negative_Words** : Binaire (0 ou 1)

3. **Has_Urgent_Keywords** : D√©tection d'id√©es suicidaires ‚ö†Ô∏è
   - Liste : `['suicide', 'kill', 'die', 'death', 'end it', 'hurt myself']`
   - Tr√®s important pour la s√©curit√©

4. **Exclamation_Count** : Nombre de `!` (peut indiquer l'intensit√© √©motionnelle)

5. **Question_Count** : Nombre de `?` (peut indiquer l'anxi√©t√©)

**Conseil :** V√©rifiez la corr√©lation de ces features avec la target.
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.3 : Recipe 1 - Dates & Time Features
**Objectif :** Extraire des patterns temporels.

**Features Temporelles √† cr√©er :**
1. Convertir `Horodatage` en datetime
2. **Hour** : Heure du post (0-23)
3. **DayOfWeek** : Jour de la semaine (0=Lundi, 6=Dimanche)
4. **Is_Weekend** : Binaire (1 si samedi/dimanche)
5. **Is_Night** : Binaire (1 si entre 22h et 6h)
6. **Is_Morning** / **Is_Afternoon** / **Is_Evening** (optionnel)

**Hypoth√®se M√©tier :** Les posts nocturnes ou du week-end peuvent indiquer une d√©tresse.
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.4 : Recipe 2 - Categories (Plateforme)
**Objectif :** Encoder `Plateforme`.

**Approche :**
- One-Hot Encoding (`pd.get_dummies`) est recommand√©.
- R√©sultat : Colonnes `Platform_Reddit`, `Platform_Twitter`, etc.

**Livrables attendus :**
- Colonnes binaires pour chaque plateforme.
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 2.5 : Final Prep
**Objectif :** Pr√©parer X et y pour la mod√©lisation.

**√âtapes :**
1. Supprimer les colonnes non n√©cessaires : `ID_Post`, `Texte`, `Horodatage`, `DayOfWeek` (si redondant)
2. Cr√©er `X` (features) et `y` (target = `Etiquette`)
3. V√©rifier qu'il n'y a pas de NaN dans X

**Livrables attendus :**
- `X` : DataFrame avec toutes les features num√©riques
- `y` : Series avec les √©tiquettes
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
---

### üìã SESSION 3 : Building & Trusting Your Model

#### √âtape 3.1 : Split Stratifi√©
**Objectif :** Diviser Train/Test en gardant la m√™me proportion de chaque classe.

**Contrainte :** Utilisez `stratify=y` dans `train_test_split`.

**Livrables attendus :**
- X_train, X_test, y_train, y_test (80/20 split recommand√©)
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 3.2 : Entra√Ænement Multi-Classe
**Objectif :** Entra√Æner un mod√®le capable de pr√©dire 3 cat√©gories.

**Mod√®le recommand√© :** `RandomForestClassifier`
- G√®re nativement la multi-classe
- Pas besoin de SMOTE (d√©s√©quilibre l√©ger)
- Option : `class_weight='balanced'` si vous voulez augmenter le poids des classes minoritaires

**Alternatives (pour comparaison) :**
- Logistic Regression (rapide, interpr√©table)
- SVC (Support Vector Classifier)

**Livrables attendus :**
- Mod√®le entra√Æn√©
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### √âtape 3.3 : √âvaluation Multi-Classe
**Objectif :** Valider la capacit√© de d√©tection sur les 3 classes.

**M√©triques √† calculer :**
1. **Accuracy** : Pourcentage global correct
2. **Classification Report** : Precision, Recall, F1-Score **par classe**
   - Focus sur F1-Score pour `Depressed` et `Anxious`
3. **Confusion Matrix** : Visualiser o√π le mod√®le se trompe
   - Axes : [Normal, Depressed, Anxious]

**Questions cl√©s :**
- Quelle classe est la mieux pr√©dite ?
- Le mod√®le confond-il `Depressed` et `Anxious` entre elles ?
- Y a-t-il beaucoup de faux n√©gatifs pour les classes critiques ?

**Conseil :** Utilisez `sns.heatmap()` pour une matrice de confusion visuelle avec annotations.
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
---

### üéÅ Part 4: Going Further (Bonus Tasks)

#### Bonus Task 1: Analyser les Tendances d'Humeur par Moment de la Journ√©e
**Goal:** Identifier les p√©riodes √† risque (ex: plus de d√©pression la nuit ?).

**Approach:**
1. Recharger les donn√©es originales pour avoir `Hour` et `Etiquette`
2. Grouper par `Hour` et `Etiquette`
3. Cr√©er un line plot ou heatmap montrant la distribution horaire

**Livrables attendus :**
- Graphique montrant les tendances par heure
- Insights : Y a-t-il un pic de posts anxieux la nuit ?
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### Bonus Task 2: Identifier les Mots D√©clencheurs pour Chaque Cat√©gorie
**Goal:** Quels mots apparaissent le plus souvent dans chaque cat√©gorie ?

**Approach:**
1. S√©parer le texte par √©tiquette
2. Tokenizer (split, lower, enlever stopwords basiques)
3. Utiliser `Counter` pour compter les mots
4. Afficher Top 10-15 mots par cat√©gorie

**Librairie sugg√©r√©e :** `from collections import Counter`

**Optionnel Avanc√© :** 
- TF-IDF pour identifier les mots discriminants
- WordCloud par cat√©gorie

**Livrables attendus :**
- Liste des mots d√©clencheurs pour `Normal`, `Depressed`, `Anxious`
- Insights : Quels mots sont uniques √† chaque cat√©gorie ?
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### Bonus Task 3: Regrouper les Utilisateurs en Groupes de Soutien
**Goal:** Identifier des profils similaires via clustering.

**Approach:**
1. S√©lectionner les features pertinentes pour le clustering :
   - `Sentiment_Polarity`, `Negative_Word_Count`, `Is_Night`, `Word_Count`
2. Normaliser les features (StandardScaler recommand√©)
3. Appliquer KMeans avec 3-4 clusters
4. Analyser chaque cluster :
   - Composition en termes d'√©tiquettes
   - Caract√©ristiques moyennes

**Why it matters:** 
- Cr√©er des groupes de soutien homog√®nes
- Ex: "Anxieux nocturnes", "D√©prim√©s expressifs", etc.

**Livrables attendus :**
- Clusters assign√©s
- Visualisation (scatter plot : Polarity vs Negative_Word_Count, color√© par cluster)
- Profil de chaque cluster
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
#### Bonus Task 4: D√©tecter les Cas Urgents
**Goal:** Syst√®me d'alerte pour les posts √† risque suicidaire.

**Approach:**
1. Utiliser la feature `Has_Urgent_Keywords` cr√©√©e pr√©c√©demment
2. Filtrer les posts avec `Has_Urgent_Keywords == 1`
3. Afficher un tableau r√©capitulatif :
   - ID_Post
   - Texte
   - Etiquette
   - Horodatage
4. Recommandations automatiques : "Contact ligne d'√©coute", "Alerte mod√©rateur"

**Why it matters:** Priorit√© absolue - intervention imm√©diate pour sauver des vies.

**Livrables attendus :**
- Nombre de cas urgents d√©tect√©s
- Tableau d√©taill√©
- Syst√®me de recommandation automatique
"""))
    
    cells.append(nbf.v4.new_code_cell("# Votre code ici"))
    
    cells.append(nbf.v4.new_markdown_cell("""
---

## üéâ Projet Compl√©t√© !

**Comp√©tences acquises :**
- ‚úÖ Feature Engineering NLP avanc√©
- ‚úÖ Analyse de sentiment avec TextBlob
- ‚úÖ Classification multi-classe
- ‚úÖ D√©tection d'urgences en sant√© mentale

**Next Steps :**
- Testez des mod√®les de deep learning (LSTM, BERT)
- Int√©grez un syst√®me de recommandation personnalis√©
- D√©ployez une API de pr√©diction en temps r√©el
"""))
    
    nb['cells'] = cells
    nbf.write(nb, 'Projet_08_Intermediaire.ipynb')
    print("‚úÖ Notebook interm√©diaire g√©n√©r√© : Projet_08_Intermediaire.ipynb")

if __name__ == "__main__":
    generer_notebook_intermediaire()
