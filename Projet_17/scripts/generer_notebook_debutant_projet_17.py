import nbformat as nbf

def generer_notebook_debutant():
    nb = nbf.v4.new_notebook()
    
    # Titre
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ›’ PROJET 17 : OPTIMISEUR DE STOCK PÃ‰RISSABLE ğŸ¥¬

Bienvenue dans ce projet crucial pour les supermarchÃ©s et Ã©piceries !

**Le ProblÃ¨me :** Les produits frais (tomates, lait, bananes...) pÃ©rissent rapidement.
- Commander TROP = âŒ Gaspillage (les produits pourrissent)
- Commander PEU = âŒ Ventes perdues (rupture de stock)

**Votre Mission :** PrÃ©dire combien d'unitÃ©s vous allez vendre DEMAIN pour chaque produit. Ainsi, vous commanderez la quantitÃ© parfaite ! ğŸ¯

---

## ğŸ“… VOTRE PROGRAMME

### ğŸ“‹ SESSION 1 : From Raw Data to Clean Insights (45 min)
- **Part 1: The Setup** - Charger les donnÃ©es de ventes historiques
- **Part 2: The Sanity Check** - Nettoyer les stocks manquants
- **Part 3: Exploratory Data Analysis** - Quels produits se vendent le mieux ?

### ğŸ“‹ SESSION 2 : The Art of Feature Engineering (45 min)
- **Part 1: The Concept** - Transformer les dates et la mÃ©tÃ©o en variables
- **Part 2: The Lab** - CrÃ©er des moyennes mobiles (tendances)
- **Part 3: Final Prep** - PrÃ©parer les donnÃ©es pour l'IA

### ğŸ“‹ SESSION 3 : Building & Trusting Your Model (45 min)
- **Part 1: The Split** - SÃ©parer entraÃ®nement et test
- **Part 2: Training** - EntraÃ®ner le modÃ¨le prÃ©dictif
- **Part 3: Evaluation** - Quelle est notre prÃ©cision ?
- **Part 4: Going Further (BONUS)** - Calculer la quantitÃ© optimale Ã  commander

---
"""))

    # SESSION 1
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ“‹ SESSION 1 : FROM RAW DATA TO CLEAN INSIGHTS
"""))

    # Part 1
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ Part 1: The Setup (10 min)

Importons nos outils et chargeons les donnÃ©es de ventes.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

print("âœ… Librairies importÃ©es !")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### ğŸ“‚ Chargement du fichier stock_perissable.csv
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df = pd.read_csv('stock_perissable.csv')

print("AperÃ§u des donnÃ©es :")
display(df.head(10))

print("\\nInfos techniques :")
df.info()
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
> **ğŸ’¡ Tip:** Le dataset contient :
> - **Date** : Jour de vente
> - **Item** : Produit (Tomato, Banana, Milk, Spinach)
> - **Stock_Initial** : QuantitÃ© en rayon au dÃ©but de la journÃ©e
> - **Meteo** : MÃ©tÃ©o (Hot, Cold, Mild)
> - **Jour_Ferie** : 1 si jour fÃ©riÃ©, 0 sinon
> - **Sold** : ğŸ¯ NOTRE CIBLE (QuantitÃ© vendue)
"""))

    # Part 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ§¹ Part 2: The Sanity Check (15 min)

### 1. Valeurs manquantes
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
print("Valeurs manquantes par colonne :")
print(df.isnull().sum())
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
> **âš ï¸ Warning:** Certaines lignes ont `Stock_Initial` ou `Meteo` manquants. Pour simplifier, on va les supprimer (car difficile d'imputer sans introduire de biais).
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Supprimer les lignes avec des valeurs manquantes
df = df.dropna()

print(f"âœ… Nouvelles dimensions : {df.shape}")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### 2. Conversion de la date
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df['Date'] = pd.to_datetime(df['Date'])
print("âœ… Date convertie en format datetime !")
"""))

    # Part 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ“Š Part 3: Exploratory Data Analysis (20 min)

### ğŸ“ˆ Ventes par Produit
Quel produit se vend le plus ?
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(10, 5))
sns.barplot(data=df, x='Item', y='Sold', estimator=np.mean, errorbar=None)
plt.title('Vente Moyenne par Produit')
plt.ylabel('UnitÃ©s Vendues (Moyenne)')
plt.show()
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
â“ **Question :** Quel produit a le volume de vente le plus Ã©levÃ© en moyenne ?

### ğŸŒ¦ï¸ Impact de la MÃ©tÃ©o
La mÃ©tÃ©o influence-t-elle les ventes ?
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(10, 5))
sns.barplot(data=df, x='Meteo', y='Sold', hue='Item', errorbar=None)
plt.title('Ventes par MÃ©tÃ©o et Produit')
plt.show()
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
â“ **Question :** Remarquez-vous un pattern ? (Ex: Plus de soupes vendues quand il fait froid ?)
"""))

    # SESSION 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ“‹ SESSION 2 : THE ART OF FEATURE ENGINEERING
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ§  Part 1: The Concept (10 min)

Pour prÃ©dire les ventes de demain, le modÃ¨le a besoin de "signaux" :
- **Le jour de la semaine** (les ventes sont plus Ã©levÃ©es le week-end)
- **La saison / le mois** (les glaces se vendent mieux l'Ã©tÃ©)
- **Les tendances rÃ©centes** (si les ventes augmentent depuis 3 jours...)
"""))

    # Part 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ§ª Part 2: The Lab - Choose Your Recipe (30 min)

### Recipe 1: Dates & Time ğŸ•
Extrayons des informations de la date.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Extraction de features temporelles
df['Jour'] = df['Date'].dt.day
df['Mois'] = df['Date'].dt.month
df['JourSemaine'] = df['Date'].dt.dayofweek  # 0=Lundi, 6=Dimanche
df['Is_Weekend'] = (df['JourSemaine'] >= 5).astype(int)  # 1 si samedi/dimanche

print("âœ… Features temporelles crÃ©Ã©es !")
display(df[['Date', 'Mois', 'JourSemaine', 'Is_Weekend']].head())
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Recipe 2: Categories ğŸ·ï¸
Encodons les catÃ©gories (`Item` et `Meteo`).
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# One-Hot Encoding
df = pd.get_dummies(df, columns=['Item', 'Meteo'], prefix=['Item', 'Meteo'])

print("âœ… Encodage terminÃ© !")
display(df.head())
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Recipe 6: Domain-Specific Features ğŸ¯
CrÃ©ons des features mÃ©tier.

#### ğŸ”¹ Moyenne Mobile (Tendance rÃ©cente)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Tri par date pour calculer les moyennes mobiles
df = df.sort_values('Date').reset_index(drop=True)

# Moyenne mobile sur 7 jours (tendance de la semaine)
# TODO: Cette feature nÃ©cessite un groupby par Item, mais nos Item sont maintenant encodÃ©s
# Pour simplifier, on calcule une moyenne globale
df['Sold_MA7'] = df['Sold'].shift(1).rolling(window=7, min_periods=1).mean()

print("âœ… Moyenne mobile crÃ©Ã©e !")
"""))

    # Part 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ Part 3: Final Prep (5 min)

Supprimons les colonnes inutiles et prÃ©parons le dataset final.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Colonnes Ã  supprimer
cols_to_drop = ['Date']  # On garde tout le reste

df_model = df.drop(columns=cols_to_drop)

# Supprimer les lignes avec NaN (crÃ©Ã©es par rolling)
df_model = df_model.dropna()

print(f"âœ… Dataset prÃªt ! Dimensions : {df_model.shape}")
"""))

    # SESSION 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ“‹ SESSION 3 : BUILDING & TRUSTING YOUR MODEL
"""))

    # Part 1
    nb.cells.append(nbf.v4.new_markdown_cell("""
## âœ‚ï¸ Part 1: The Split (10 min)

SÃ©parons les features (X) et la cible (y).
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
from sklearn.model_selection import train_test_split

X = df_model.drop('Sold', axis=1)
y = df_model['Sold']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Train size: {X_train.shape}")
print(f"Test size: {X_test.shape}")
"""))

    # Part 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ‹ï¸ Part 2: Training (15 min)

EntraÃ®nons un **RandomForestRegressor**.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=42)

print("â³ EntraÃ®nement...")
model.fit(X_train, y_train)
print("âœ… ModÃ¨le entraÃ®nÃ© !")
"""))

    # Part 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ¯ Part 3: Evaluation (20 min)

Ã‰valuons la prÃ©cision du modÃ¨le.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"ğŸ“Š MAE (Erreur Moyenne) : {mae:.2f} unitÃ©s")
print(f"ğŸ“Š RMSE : {rmse:.2f}")
print(f"ğŸ“Š RÂ² Score : {r2:.3f}")

# Visualisation
plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Ventes RÃ©elles')
plt.ylabel('Ventes PrÃ©dites')
plt.title('VÃ©ritÃ© vs PrÃ©diction')
plt.show()
"""))

    # Part 4 Bonus
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ Part 4: Going Further (Bonus - 15-30 mins)

### Bonus Task 1: Calculer la QuantitÃ© de Commande Optimale ğŸ“¦

**Goal:** Recommander combien commander pour demain.

**Why it matters:** Si on prÃ©dit 30 ventes mais on en vend parfois 35, on aura une rupture de stock. Il faut une **marge de sÃ©curitÃ©**.

**Approach:**
1. PrÃ©dire les ventes moyennes
2. Calculer l'Ã©cart-type (volatilitÃ©)
3. Commande Optimale = PrÃ©diction + (1.5 Ã— Ã‰cart-type)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# TODO: Calculer l'Ã©cart-type des erreurs de prÃ©diction
errors = y_test - y_pred
std_error = errors.std()

print(f"Ã‰cart-type des erreurs : {std_error:.2f}")

# Exemple : Si on prÃ©dit 30 unitÃ©s demain
predicted_sales = 30
safety_margin = 1.5 * std_error
optimal_order = predicted_sales + safety_margin

print(f"\\nğŸ“¦ PrÃ©diction : {predicted_sales} unitÃ©s")
print(f"ğŸ“¦ Marge de sÃ©curitÃ© : +{safety_margin:.2f}")
print(f"ğŸ“¦ QuantitÃ© Ã  commander : {optimal_order:.0f} unitÃ©s")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: Identifier les Articles Ã  Rotation Lente ğŸŒ

**Goal:** Trouver les produits qui se vendent peu (candidats pour les soldes).
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Revenir au dataset original pour cette analyse
df_original = pd.read_csv('stock_perissable.csv').dropna()

avg_sales_by_item = df_original.groupby('Item')['Sold'].mean().sort_values()

print("Vente moyenne par produit :")
print(avg_sales_by_item)

# Les produits en dessous de 30 unitÃ©s/jour sont considÃ©rÃ©s lents
slow_movers = avg_sales_by_item[avg_sales_by_item < 30]
print(f"\\nğŸŒ Articles Ã  rotation lente : {list(slow_movers.index)}")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 3: DÃ©tecter les Ruptures de Stock ğŸš¨

**Goal:** Identifier les jours oÃ¹ nous avons manquÃ© de stock.

**Approach:** Si `Stock_Initial` < `Sold`, alors nous avons eu une rupture.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# DÃ©tecter les ruptures (impossible de vendre plus que le stock initial)
# En rÃ©alitÃ©, si Stock_Initial est proche de Sold, c'est suspect
df_original['Rupture_Probable'] = (df_original['Stock_Initial'] <= df_original['Sold'] * 1.1).astype(int)

ruptures = df_original[df_original['Rupture_Probable'] == 1]
print(f"Nombre de ruptures probables dÃ©tectÃ©es : {len(ruptures)}")

# Top des jours avec ruptures
print("\\nExemples de ruptures :")
display(ruptures[['Date', 'Item', 'Stock_Initial', 'Sold']].head(10))
"""))

    # Sauvegarde
    with open('Projet_17_Stock_Perissable_Debutant.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)

if __name__ == "__main__":
    generer_notebook_debutant()
