import nbformat as nbf

def generer_notebook_debutant():
    nb = nbf.v4.new_notebook()
    
    cells = []
    
    # --- Titre et Introduction ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ¥— Projet 7 : PrÃ©vision du Gaspillage Alimentaire
## Version DÃ©butant - "Je te montre, puis tu rÃ©pÃ¨tes"

---

### ðŸŽ¯ L'Objectif de ce Projet

Le gaspillage alimentaire coÃ»te cher aux supermarchÃ©s et nuit Ã  l'environnement. Votre mission est de **prÃ©dire les unitÃ©s vendues** pour optimiser les commandes et rÃ©duire les pertes.

**Ce que vous allez apprendre :**
- ðŸ“Š Analyser des donnÃ©es temporelles (dates, saisonnalitÃ©)
- ðŸ§® CrÃ©er des features Ã  partir de dates (jour, mois, jour de la semaine)
- ðŸ“‰ ModÃ©liser un problÃ¨me de **RÃ©gression** (prÃ©dire une quantitÃ©)
- ðŸŽ¯ Ã‰valuer avec MAE et RÂ² Score

---

> **ðŸ’¡ Comment utiliser ce notebook :**
> 1. **Les cellules avec du code complet** â†’ Lisez et exÃ©cutez-les pour voir l'exemple
> 2. **Les cellules avec # TODO** â†’ C'est votre tour ! RÃ©pÃ©tez la technique
> 3. **Les Questions â“** â†’ RÃ©flÃ©chissez avant de passer Ã  la suite

---
"""))

    # --- SESSION 1 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ“‹ SESSION 1 : From Raw Data to Clean Insights (45 min)

## Part 1: The Setup (10 min)

### ðŸ“˜ Theory: Les BibliothÃ¨ques
"""))

    cells.append(nbf.v4.new_code_cell("""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Configuration
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12
sns.set_style("whitegrid")

print("âœ… BibliothÃ¨ques importÃ©es !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã‰tape 1.1 : Charger les DonnÃ©es
Le fichier est `gaspillage_alimentaire.csv`.
"""))

    cells.append(nbf.v4.new_code_cell("""
df = pd.read_csv('gaspillage_alimentaire.csv')

print("ðŸ“Š AperÃ§u des donnÃ©es :")
display(df.head())
print(f"\\nâœ… Dimensions : {df.shape[0]} lignes, {df.shape[1]} colonnes")
print(f"\\nðŸ“‹ Colonnes : {list(df.columns)}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: The Sanity Check (15 min)

### ðŸ“˜ Theory: Valeurs Manquantes
VÃ©rifions si nous avons des trous dans nos donnÃ©es.
"""))

    cells.append(nbf.v4.new_code_cell("""
print("ðŸ” Valeurs manquantes par colonne :")
print(df.isnull().sum())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Exemple : Remplir les Prix Manquants
Pour le prix, nous allons utiliser la **mÃ©diane par produit**.
"""))

    cells.append(nbf.v4.new_code_cell("""
# Remplir Price par la mÃ©diane de chaque produit
df['Price'] = df.groupby('ID_Produit')['Price'].transform(lambda x: x.fillna(x.median()))

print("âœ… Prix remplis avec la mÃ©diane par produit")
print(f"Valeurs manquantes restantes dans Price : {df['Price'].isnull().sum()}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
Remplissez les valeurs manquantes de `Discount` avec la **mÃ©diane globale**.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Remplir Discount avec la mÃ©diane

# mediane_discount = df['Discount'].median()
# df['Discount'].fillna(mediane_discount, inplace=True)
# print(f"âœ… Discount rempli avec : {mediane_discount}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Exploratory Data Analysis (20 min)

### ðŸ“Š Visualisation 1 : Distribution des UnitÃ©s Vendues
Notre variable cible !
"""))

    cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(10, 5))
sns.histplot(df['Unites_Vendues'], bins=50, kde=True, color='green')
plt.title('ðŸ“ˆ Distribution des UnitÃ©s Vendues')
plt.xlabel('UnitÃ©s Vendues')
plt.ylabel('FrÃ©quence')
plt.show()

print(f"Moyenne : {df['Unites_Vendues'].mean():.2f}")
print(f"MÃ©diane : {df['Unites_Vendues'].median():.2f}")
print(f"Min : {df['Unites_Vendues'].min()}, Max : {df['Unites_Vendues'].max()}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ“Š Visualisation 2 : Ventes par Produit
Quels produits se vendent le plus ?
"""))

    cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(10, 5))
sns.boxplot(data=df, x='ID_Produit', y='Unites_Vendues', palette='Set2')
plt.title('ðŸ“¦ Ventes par Type de Produit')
plt.ylabel('UnitÃ©s Vendues')
plt.xticks(rotation=45)
plt.show()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### â“ Question
Quel produit a les ventes les plus variables ? Le moins prÃ©visible ?
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
Visualisez l'impact du `Discount` sur les ventes avec un **Scatterplot**.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Scatterplot Discount vs Unites_Vendues

# plt.figure(figsize=(10, 5))
# sns.scatterplot(data=df, x='Discount', y='Unites_Vendues', alpha=0.5)
# plt.title('ðŸ’° Impact des RÃ©ductions sur les Ventes')
# plt.xlabel('Taux de RÃ©duction')
# plt.ylabel('UnitÃ©s Vendues')
# plt.show()
"""))

    # --- SESSION 2 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ“‹ SESSION 2 : The Art of Feature Engineering (45 min)

## Part 1: The Concept (10 min)

Les ventes alimentaires dÃ©pendent du **temps** (jour de la semaine, saison) et des **promotions**. Transformons ces informations en features numÃ©riques !

## Part 2: The Lab - Choose Your Recipe (30 min)

### ðŸ“… Recipe 1: Time-Based Features

#### ðŸ“˜ Theory: Features Temporelles
Ã€ partir de la colonne `Date`, nous pouvons extraire :
- Le jour de la semaine (Lundi = 0, Dimanche = 6)
- Le mois de l'annÃ©e (1-12)
- Est-ce un weekend ? (Samedi/Dimanche)
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Exemple : Extraire des Features de Date
"""))

    cells.append(nbf.v4.new_code_cell("""
# Convertir Date en datetime
df['Date'] = pd.to_datetime(df['Date'])

# Feature 1: Jour de la semaine (0=Lundi, 6=Dimanche)
df['Jour_Semaine'] = df['Date'].dt.dayofweek

# Feature 2: Mois
df['Mois'] = df['Date'].dt.month

# Feature 3: Est weekend (1=oui, 0=non)
df['Est_Weekend'] = (df['Jour_Semaine'] >= 5).astype(int)

print("âœ… Features temporelles crÃ©Ã©es !")
display(df[['Date', 'Jour_Semaine', 'Mois', 'Est_Weekend']].head())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
CrÃ©ez une feature `Jours_Avant_Expiration` = nombre de jours entre `Date` et `Date_Expiration`.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: CrÃ©er Jours_Avant_Expiration

# df['Date_Expiration'] = pd.to_datetime(df['Date_Expiration'])
# df['Jours_Avant_Expiration'] = (df['Date_Expiration'] - df['Date']).dt.days
# print("âœ… Feature Jours_Avant_Expiration crÃ©Ã©e !")
# display(df[['Date', 'Date_Expiration', 'Jours_Avant_Expiration']].head())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ·ï¸ Recipe 2: Categories (One-Hot Encoding)

Le `ID_Produit` est catÃ©goriel (Bread, Milk, etc.). Encodons-le !
"""))

    cells.append(nbf.v4.new_code_cell("""
# One-Hot Encoding de ID_Produit
df = pd.get_dummies(df, columns=['ID_Produit'], prefix='Produit')

print("âœ… Encodage terminÃ© !")
print(f"Nouvelles colonnes crÃ©Ã©es : {[col for col in df.columns if 'Produit_' in col]}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### âž— Recipe 4: Math Magic

#### ðŸ“˜ Theory: Interaction Features
Parfois, combiner deux features donne plus d'info. Par exemple :
- **Prix Effectif** = Price Ã— (1 - Discount)
"""))

    cells.append(nbf.v4.new_code_cell("""
# Calculer le prix aprÃ¨s rÃ©duction
df['Prix_Effectif'] = df['Price'] * (1 - df['Discount'])

print("âœ… Feature Prix_Effectif crÃ©Ã©e !")
display(df[['Price', 'Discount', 'Prix_Effectif']].head())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
CrÃ©ez une feature binaire `Promo_Forte` (1 si Discount > 0.3, sinon 0).
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: CrÃ©er Promo_Forte

# df['Promo_Forte'] = (df['Discount'] > 0.3).astype(int)
# print("âœ… Feature Promo_Forte crÃ©Ã©e !")
# print(df['Promo_Forte'].value_counts())
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Final Prep (5 min)

PrÃ©parons X et y pour le modÃ¨le.
"""))

    cells.append(nbf.v4.new_code_cell("""
# SÃ©lectionner features numÃ©riques (retirer Date, Date_Expiration)
features_to_drop = ['Date', 'Date_Expiration', 'Unites_Vendues']
features_to_drop = [col for col in features_to_drop if col in df.columns]

X = df.drop(columns=features_to_drop)
y = df['Unites_Vendues']

print(f"âœ… PrÃªt ! X shape: {X.shape}, y shape: {y.shape}")
print(f"Features utilisÃ©es : {list(X.columns)}")
"""))

    # --- SESSION 3 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ðŸ“‹ SESSION 3 : Building & Trusting Your Model (45 min)

## Part 1: The Split (10 min)

Divisons nos donnÃ©es en Train (80%) et Test (20%).
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"âœ… Train set : {X_train.shape[0]} lignes")
print(f"âœ… Test set  : {X_test.shape[0]} lignes")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: Training (15 min)

Nous allons utiliser un **RandomForestRegressor** (rÃ©gression, pas classification).
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.ensemble import RandomForestRegressor

# CrÃ©er le modÃ¨le
model = RandomForestRegressor(n_estimators=100, random_state=42)

# EntraÃ®ner
print("ðŸš€ EntraÃ®nement en cours...")
model.fit(X_train, y_train)
print("âœ… ModÃ¨le entraÃ®nÃ© !")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Evaluation (20 min)

### ðŸ“˜ Theory: MÃ©triques de RÃ©gression
Pour la **RÃ©gression**, nous utilisons :
- **MAE (Mean Absolute Error)** : Erreur moyenne en unitÃ©s (facile Ã  comprendre)
- **RMSE (Root Mean Squared Error)** : PÃ©nalise plus les grosses erreurs
- **RÂ² Score** : Pourcentage de variance expliquÃ©e (0-1, plus proche de 1 = mieux)

> **ðŸ’¡ Tip:** Pour le gaspillage alimentaire, le MAE est plus parlant : "On se trompe de X unitÃ©s en moyenne".
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# PrÃ©dictions
y_pred = model.predict(X_test)

# MÃ©triques
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"ðŸ“Š MAE  : {mae:.2f} unitÃ©s")
print(f"ðŸ“Š RMSE : {rmse:.2f} unitÃ©s")
print(f"ðŸ“Š RÂ²   : {r2:.3f}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ“Š Visualisation : PrÃ©dictions vs RÃ©el
"""))

    cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Ventes RÃ©elles')
plt.ylabel('Ventes PrÃ©dites')
plt.title('ðŸŽ¯ QualitÃ© des PrÃ©dictions')
plt.show()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ðŸ› ï¸ Ã€ vous de jouer !
Affichez les **Features Importantes** pour voir ce qui influence le plus les ventes.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Plot Feature Importance

# importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)
# plt.figure(figsize=(10, 6))
# importances.plot(kind='barh', color='teal')
# plt.title('ðŸ”‘ Top 10 Features Importantes')
# plt.xlabel('Importance')
# plt.show()
"""))

    # --- PART 4 BONUS ---
    cells.append(nbf.v4.new_markdown_cell("""
## ðŸŽ Part 4: Going Further (Bonus - 15-30 mins)

### Bonus Task 1: Analyse Temporelle

**Goal:** Visualiser les ventes au fil du temps pour dÃ©tecter des tendances saisonniÃ¨res.

**Approach:**
1. Grouper les ventes par `Date`
2. CrÃ©er une courbe temporelle
3. Identifier les pics (fÃªtes, weekends)
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Analyse temporelle

# ventes_par_jour = df.groupby('Date')['Unites_Vendues'].sum().reset_index()
# plt.figure(figsize=(14, 6))
# plt.plot(ventes_par_jour['Date'], ventes_par_jour['Unites_Vendues'], linewidth=2)
# plt.title('ðŸ“† Ã‰volution des Ventes dans le Temps')
# plt.xlabel('Date')
# plt.ylabel('UnitÃ©s Vendues Totales')
# plt.xticks(rotation=45)
# plt.show()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: Optimisation du Stock

**Goal:** Calculer le stock optimal pour minimiser le gaspillage.

**Approach:**
1. Pour chaque produit, prÃ©dire les ventes moyennes
2. Ajouter une marge de sÃ©curitÃ© (ex: +10%)
3. Recommandation de commande
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Recommandations de stock

# # PrÃ©dire sur toutes les donnÃ©es (ou un nouveau mois)
# predictions = model.predict(X)
# df['Ventes_Predites'] = predictions

# # Stock recommandÃ© par produit
# stock_recommande = df.groupby('ID_Produit')['Ventes_Predites'].mean() * 1.1  # +10% marge
# print("ðŸ›’ Stock RecommandÃ© par Produit :")
# print(stock_recommande)
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 3: DÃ©tection d'Anomalies

**Goal:** Identifier les jours avec des ventes inhabituellement hautes ou basses.

**Approach:**
1. Calculer la moyenne et l'Ã©cart-type des ventes
2. Marquer les anomalies (ventes > moyenne + 2Ã—Ã©cart-type OU < moyenne - 2Ã—Ã©cart-type)
3. Investiguer ces jours
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: DÃ©tection d'anomalies

# moyenne = df['Unites_Vendues'].mean()
# ecart_type = df['Unites_Vendues'].std()

# df['Anomalie'] = ((df['Unites_Vendues'] > moyenne + 2*ecart_type) | 
#                   (df['Unites_Vendues'] < moyenne - 2*ecart_type))

# print(f"ðŸš¨ Nombre d'anomalies dÃ©tectÃ©es : {df['Anomalie'].sum()}")
# display(df[df['Anomalie']][['Date', 'ID_Produit', 'Unites_Vendues', 'Discount']])
"""))

    nb['cells'] = cells
    
    with open('Projet_07_Debutant.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    print("âœ… Notebook DÃ©butant gÃ©nÃ©rÃ© : Projet_07_Debutant.ipynb")

if __name__ == "__main__":
    generer_notebook_debutant()
