import nbformat as nbf

def generer_notebook_intermediaire():
    nb = nbf.v4.new_notebook()
    
    cells = []
    
    # --- Titre et Introduction ---
    cells.append(nbf.v4.new_markdown_cell("""
# ü•ó Projet 7 : Pr√©vision du Gaspillage Alimentaire
## Version Interm√©diaire - "Tu explores, j'oriente"

---

### üéØ L'Objectif de ce Projet

R√©duire le gaspillage alimentaire en pr√©disant pr√©cis√©ment les ventes futures pour optimiser les commandes. Vous devrez explorer les donn√©es, identifier les patterns et construire un mod√®le de pr√©vision robuste.

**Ce que vous allez ma√Ætriser :**
- üìä Analyse exploratoire approfondie de donn√©es temporelles
- üîß Feature engineering avanc√© (features temporelles, interactions)
- ü§ñ Optimisation de mod√®le et s√©lection de features
- üìà Validation et interpr√©tation des r√©sultats

---

> **üí° Format de ce notebook :**
> - **Consignes claires** : Chaque section indique ce qu'il faut faire
> - **Code √† compl√©ter** : Des TODO pour vous guider
> - **Libert√© d'exploration** : Essayez diff√©rentes approches !

---
"""))

    # --- SESSION 1 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 1 : From Raw Data to Clean Insights (45 min)

## Part 1: The Setup (5 min)

**Consigne :** Importez les biblioth√®ques n√©cessaires et chargez `gaspillage_alimentaire.csv`.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Importer pandas, numpy, matplotlib, seaborn, datetime

# TODO: Charger le dataset

# TODO: Afficher les premi√®res lignes et les informations
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: The Sanity Check (15 min)

**Consigne :** Analysez les valeurs manquantes et traitez-les intelligemment.

**Approche recommand√©e :**
1. Identifiez les colonnes avec valeurs manquantes
2. Pour `Price` et `Discount`, utilisez des m√©thodes par groupe (par produit)
3. V√©rifiez qu'aucune valeur manquante ne reste
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Analyser les valeurs manquantes

# TODO: Remplir Price avec la m√©diane par ID_Produit

# TODO: Remplir Discount avec la m√©diane globale

# TODO: V√©rifier qu'il n'y a plus de NaN
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Exploratory Data Analysis (25 min)

**Consigne :** Cr√©ez 4 visualisations pour comprendre les donn√©es :

1. **Distribution de la cible** (`Unites_Vendues`)
2. **Ventes par produit** (boxplot ou violin plot)
3. **Impact du discount** (scatterplot avec couleurs par produit)
4. **√âvolution temporelle** (ventes totales par jour)

**Questions cl√©s √† r√©pondre :**
- Y a-t-il des valeurs aberrantes (outliers) ?
- Quel produit est le plus stable/variable ?
- Les promotions augmentent-elles vraiment les ventes ?
- Voyez-vous une saisonnalit√© ou une tendance ?
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Visualisation 1 - Distribution des ventes

# TODO: Visualisation 2 - Ventes par produit

# TODO: Visualisation 3 - Impact du discount

# TODO: Visualisation 4 - √âvolution temporelle
"""))

    # --- SESSION 2 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 2 : The Art of Feature Engineering (45 min)

## Part 1: The Concept (5 min)

Les ventes alimentaires sont influenc√©es par :
- **Le temps** : jour de la semaine, mois, saison
- **La fra√Æcheur** : jours avant expiration
- **Les promotions** : discount, prix effectif
- **Le produit** : type de produit (encodage)

Votre mission : cr√©er des features pertinentes pour capturer ces patterns.

## Part 2: The Lab - Choose Your Recipe (35 min)

### üìÖ Recipe 1: Time-Based Features (15 min)

**Consigne :** √Ä partir des colonnes `Date` et `Date_Expiration`, cr√©ez :

1. **Features de base :**
   - `Jour_Semaine` (0-6)
   - `Mois` (1-12)
   - `Jour_Mois` (1-31)
   - `Est_Weekend` (binaire)

2. **Features avanc√©es :**
   - `Jours_Avant_Expiration` (Date_Expiration - Date)
   - `Semaine_Annee` (semaine ISO)
   - `Expire_Bientot` (1 si expire dans 2 jours ou moins, sinon 0)
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Convertir Date et Date_Expiration en datetime

# TODO: Cr√©er les features temporelles de base

# TODO: Cr√©er Jours_Avant_Expiration

# TODO: Cr√©er features avanc√©es (Semaine_Annee, Expire_Bientot)

# TODO: V√©rifier les nouvelles colonnes
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### üè∑Ô∏è Recipe 2: Categories (10 min)

**Consigne :** Encodez `ID_Produit` avec **One-Hot Encoding**.

**Astuce :** Utilisez `pd.get_dummies()` avec `drop_first=True` pour √©viter la multicolin√©arit√©.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: One-Hot Encoding de ID_Produit

# TODO: Afficher les nouvelles colonnes cr√©√©es
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### ‚ûó Recipe 4: Math Magic - Interaction Features (10 min)

**Consigne :** Cr√©ez des features d'interaction :

1. `Prix_Effectif` = Price √ó (1 - Discount)
2. `Ratio_Prix_Discount` = Discount / Price (normalis√©)
3. `Promo_Forte` = 1 si Discount > 0.3, sinon 0
4. `Urgence_Vente` = Promo_Forte √ó Expire_Bientot (produit en promo ET proche expiration)
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Cr√©er Prix_Effectif

# TODO: Cr√©er Ratio_Prix_Discount

# TODO: Cr√©er Promo_Forte

# TODO: Cr√©er Urgence_Vente
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Final Prep (5 min)

**Consigne :** Pr√©parez X et y en supprimant les colonnes non pertinentes (dates brutes, ID textuels).
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Identifier les colonnes √† supprimer

# TODO: Cr√©er X (features) et y (Unites_Vendues)

# TODO: V√©rifier les dimensions et les colonnes
"""))

    # --- SESSION 3 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 3 : Building & Trusting Your Model (45 min)

## Part 1: The Split (5 min)

**Consigne :** Divisez les donn√©es en Train/Test (80/20) avec `random_state=42`.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Import train_test_split

# TODO: Cr√©er X_train, X_test, y_train, y_test

# TODO: Afficher les dimensions
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 2: Training (15 min)

### √âtape 1 : Mod√®le de Base

**Consigne :** Entra√Ænez un `RandomForestRegressor` avec les param√®tres par d√©faut + `random_state=42`.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Importer RandomForestRegressor

# TODO: Cr√©er le mod√®le

# TODO: Entra√Æner sur X_train, y_train
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 2 : Optimisation des Hyperparam√®tres (Optionnel mais recommand√©)

**Consigne :** Testez diff√©rents param√®tres pour am√©liorer le mod√®le :
- `n_estimators` : [50, 100, 200]
- `max_depth` : [10, 20, None]
- `min_samples_split` : [2, 5]

**Astuce :** Utilisez une simple boucle for et comparez les MAE.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO (Optionnel): Tester diff√©rents hyperparam√®tres

# Exemple:
# best_mae = float('inf')
# best_params = {}
# for n_est in [50, 100, 200]:
#     for max_d in [10, 20, None]:
#         model_temp = RandomForestRegressor(n_estimators=n_est, max_depth=max_d, random_state=42)
#         model_temp.fit(X_train, y_train)
#         y_pred_temp = model_temp.predict(X_test)
#         mae_temp = mean_absolute_error(y_test, y_pred_temp)
#         if mae_temp < best_mae:
#             best_mae = mae_temp
#             best_params = {'n_estimators': n_est, 'max_depth': max_d}
# print(f"Meilleurs param√®tres: {best_params} avec MAE={best_mae:.2f}")
"""))

    cells.append(nbf.v4.new_markdown_cell("""
## Part 3: Evaluation (25 min)

### √âtape 1 : M√©triques

**Consigne :** Calculez et affichez :
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)  
- R¬≤ Score
- MAPE (Mean Absolute Percentage Error) : `mean(|y_true - y_pred| / y_true) √ó 100`
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Faire les pr√©dictions sur X_test

# TODO: Calculer MAE, RMSE, R¬≤

# TODO: Calculer MAPE

# TODO: Afficher toutes les m√©triques
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 2 : Visualisation des Performances

**Consigne :** Cr√©ez 2 graphiques :

1. **Scatter Plot** : Pr√©dictions vs Valeurs R√©elles (avec ligne y=x id√©ale)
2. **Residual Plot** : Erreurs (y_test - y_pred) vs Valeurs Pr√©dites

**Interpr√©tation :** 
- Si les points sont proches de la ligne y=x ‚Üí bon mod√®le
- Si les r√©sidus sont al√©atoires autour de 0 ‚Üí pas de biais
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Graphique 1 - Pr√©dictions vs R√©el

# TODO: Graphique 2 - Residual Plot
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### √âtape 3 : Feature Importance

**Consigne :** Affichez les 15 features les plus importantes (barplot horizontal).

**Analyse :** Quelles features dominent ? Est-ce coh√©rent avec votre compr√©hension du domaine ?
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Extraire et afficher feature importances

# TODO: Cr√©er un barplot des top 15
"""))

    # --- PART 4 BONUS ---
    cells.append(nbf.v4.new_markdown_cell("""
## üéÅ Part 4: Going Further (Bonus - 30-45 mins)

### Bonus Task 1: Analyse des Erreurs

**Goal:** Identifier sur quels produits/situations le mod√®le performe mal.

**Approche:**
1. Cr√©er un DataFrame avec `y_test`, `y_pred`, erreur absolue
2. Ajouter les features originales (produit, discount, etc.)
3. Analyser :
   - Sur quel produit l'erreur moyenne est la plus haute ?
   - Les jours avec forte promo sont-ils moins bien pr√©dits ?
   - Les produits proches expiration posent-ils probl√®me ?
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Analyse des erreurs par produit et par contexte
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: Pr√©dictions pour le Mois Prochain

**Goal:** Utiliser le mod√®le pour g√©n√©rer des pr√©visions r√©alistes.

**Approche:**
1. Cr√©er un dataset fictif pour les 30 prochains jours
2. Remplir les features (dates, produits, prix moyens, discount moyen)
3. Faire des pr√©dictions
4. Visualiser les pr√©visions par produit

**Livrable:** Tableau des ventes pr√©vues par produit pour optimiser les commandes.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Cr√©er un dataset pour le mois prochain

# TODO: G√©n√©rer les pr√©dictions

# TODO: Visualiser et r√©sumer
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 3: Mod√®le de D√©tection d'Anomalies

**Goal:** Au lieu de pr√©dire les ventes, d√©tecter les jours "anormaux" o√π les ventes sont bizarrement hautes ou basses.

**Approche:**
1. Calculer les r√©sidus = y_test - y_pred
2. Marquer comme anomalie si |r√©sidu| > 2 √ó std(r√©sidus)
3. Investiguer ces jours (date, produit, discount, contexte)

**Application:** Alerter le manager quand quelque chose d'inhabituel se passe.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: D√©tection d'anomalies bas√©e sur les r√©sidus

# TODO: Analyser les anomalies d√©tect√©es
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 4: Comparaison de Mod√®les

**Goal:** Comparer `RandomForestRegressor` avec d'autres algorithmes.

**Mod√®les √† tester:**
- Linear Regression (baseline simple)
- Gradient Boosting Regressor
- XGBoost (si install√©)

**Livrable:** Tableau comparatif des MAE/R¬≤ pour chaque mod√®le.
"""))

    cells.append(nbf.v4.new_code_cell("""
# TODO: Entra√Æner et comparer plusieurs mod√®les

# from sklearn.linear_model import LinearRegression
# from sklearn.ensemble import GradientBoostingRegressor

# TODO: Cr√©er un tableau comparatif
"""))

    nb['cells'] = cells
    
    with open('Projet_07_Intermediaire.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    print("‚úÖ Notebook Interm√©diaire g√©n√©r√© : Projet_07_Intermediaire.ipynb")

if __name__ == "__main__":
    generer_notebook_intermediaire()
