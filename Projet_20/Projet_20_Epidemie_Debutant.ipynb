{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a6b594",
   "metadata": {},
   "source": [
    "\n",
    "# PROJET 20 : PREDICTION D'EPIDEMIE\n",
    "\n",
    "Bienvenue dans le dernier projet - le plus important pour la sante publique !\n",
    "\n",
    "**Le Probleme :** Les hopitaux doivent prevoir les epidemies (Grippe, Dengue) pour preparer lits et medicaments.\n",
    "\n",
    "**Votre Mission :** Predire le nombre de cas pour la semaine prochaine en analysant la meteo, Google Trends, et les donnees historiques.\n",
    "\n",
    "---\n",
    "\n",
    "## VOTRE PROGRAMME\n",
    "\n",
    "### SESSION 1 : From Raw Data to Clean Insights (45 min)\n",
    "- **Part 1: The Setup** - Charger les donnees d'epidemie\n",
    "- **Part 2: The Sanity Check** - Nettoyer les donnees manquantes\n",
    "- **Part 3: Exploratory Data Analysis** - Analyser les tendances\n",
    "\n",
    "### SESSION 2 : The Art of Feature Engineering (45 min)\n",
    "- **Part 1: The Concept** - Comprendre les series temporelles\n",
    "- **Part 2: The Lab** - Creer des lag features et moyennes mobiles\n",
    "- **Part 3: Final Prep** - Preparer le dataset\n",
    "\n",
    "### SESSION 3 : Building & Trusting Your Model (45 min)\n",
    "- **Part 1: The Split** - Train/Test split\n",
    "- **Part 2: Training** - RandomForestRegressor\n",
    "- **Part 3: Evaluation** - MAE, RMSE, R2\n",
    "- **Part 4: Going Further (BONUS)** - Prediction du pic et systeme d'alerte\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e35f5",
   "metadata": {},
   "source": [
    "\n",
    "# SESSION 1 : FROM RAW DATA TO CLEAN INSIGHTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbcddb",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: The Setup (10 min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Librairies importees !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff04787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('epidemie.csv')\n",
    "\n",
    "print(\"Apercu des donnees :\")\n",
    "display(df.head(10))\n",
    "\n",
    "print(\"\\nInfos techniques :\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b69078",
   "metadata": {},
   "source": [
    "\n",
    "> **Tip:** Le dataset contient :\n",
    "> - **Week** : Semaine (format date)\n",
    "> - **Region** : Region geographique\n",
    "> - **Temp_Moyenne** : Temperature moyenne\n",
    "> - **Precipitations** : Pluies (favorisent certaines maladies)\n",
    "> - **Google_Trends** : Recherches Google liees aux symptomes\n",
    "> - **Cases** : CIBLE (nombre de cas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58ccf7",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: The Sanity Check (15 min)\n",
    "\n",
    "### 1. Valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Valeurs manquantes par colonne :\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remplir les valeurs manquantes par la mediane\n",
    "df['Google_Trends'].fillna(df['Google_Trends'].median(), inplace=True)\n",
    "df['Precipitations'].fillna(df['Precipitations'].median(), inplace=True)\n",
    "\n",
    "print(f\"Nouvelles dimensions : {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71a5e5",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Conversion de la date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f851a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Week'] = pd.to_datetime(df['Week'])\n",
    "print(\"Week convertie en datetime !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c25107",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Exploratory Data Analysis (20 min)\n",
    "\n",
    "### Evolution des cas dans le temps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df['Week'], df['Cases'])\n",
    "plt.title('Evolution des Cas d Epidemie')\n",
    "plt.xlabel('Semaine')\n",
    "plt.ylabel('Nombre de Cas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e69da",
   "metadata": {},
   "source": [
    "\n",
    "Question : Observez-vous des pics epidemiques ?\n",
    "\n",
    "### Cas par region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df, x='Region', y='Cases', estimator=np.mean, errorbar=None)\n",
    "plt.title('Cas Moyens par Region')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4247a",
   "metadata": {},
   "source": [
    "\n",
    "# SESSION 2 : THE ART OF FEATURE ENGINEERING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b0b53",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: The Concept (10 min)\n",
    "\n",
    "Pour predire les epidemies :\n",
    "- **Lag features** : Le nombre de cas de la semaine precedente influence cette semaine\n",
    "- **Moyennes mobiles** : Tendance sur 4 semaines\n",
    "- **Saisonnalite** : Certaines maladies ont des pics saisonniers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2014ee",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: The Lab (30 min)\n",
    "\n",
    "### Recipe 1: Dates & Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275be5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Mois'] = df['Week'].dt.month\n",
    "df['Annee'] = df['Week'].dt.year\n",
    "df['Week_of_Year'] = df['Week'].dt.isocalendar().week\n",
    "\n",
    "print(\"Features temporelles creees !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c5eb6",
   "metadata": {},
   "source": [
    "\n",
    "### Recipe 2: Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.get_dummies(df, columns=['Region'], prefix='Region')\n",
    "\n",
    "print(\"Encodage termine !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99820f24",
   "metadata": {},
   "source": [
    "\n",
    "### Recipe 6: Domain-Specific Features\n",
    "\n",
    "#### Feature 1: Lag (Cas de la semaine precedente)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trier par date\n",
    "df = df.sort_values('Week').reset_index(drop=True)\n",
    "\n",
    "# Lag 1 semaine\n",
    "df['Cases_Lag1'] = df['Cases'].shift(1)\n",
    "\n",
    "print(\"Lag feature creee !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5086b",
   "metadata": {},
   "source": [
    "\n",
    "#### Feature 2: Moyenne mobile (4 semaines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Cases_MA4'] = df['Cases'].shift(1).rolling(window=4, min_periods=1).mean()\n",
    "\n",
    "print(\"Moyenne mobile creee !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c1d9b",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Final Prep (5 min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313eeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_to_drop = ['Week']\n",
    "\n",
    "df_model = df.drop(columns=cols_to_drop)\n",
    "df_model = df_model.dropna()\n",
    "\n",
    "print(f\"Dataset pret ! Dimensions : {df_model.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c01914",
   "metadata": {},
   "source": [
    "\n",
    "# SESSION 3 : BUILDING & TRUSTING YOUR MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8daf9",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: The Split (10 min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_model.drop('Cases', axis=1)\n",
    "y = df_model['Cases']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train size: {X_train.shape}\")\n",
    "print(f\"Test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93082cb9",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Training (15 min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "print(\"Entrainement...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Modele entraine !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140da8b",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Evaluation (20 min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE (Erreur Moyenne) : {mae:.2f} cas\")\n",
    "print(f\"RMSE : {rmse:.2f}\")\n",
    "print(f\"R2 Score : {r2:.3f}\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Cas Reels')\n",
    "plt.ylabel('Cas Predits')\n",
    "plt.title('Verite vs Prediction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb598d9f",
   "metadata": {},
   "source": [
    "\n",
    "## Part 4: Going Further (Bonus - 15-30 mins)\n",
    "\n",
    "### Bonus Task 1: Classifier le Niveau de Risque\n",
    "\n",
    "**Goal:** Creer une classification Faible/Moyen/Epidemique basee sur les predictions.\n",
    "\n",
    "**Why it matters:** Les hopitaux ont besoin d alertes simples, pas juste de chiffres.\n",
    "\n",
    "**Approach:**\n",
    "1. Definir seuils : Faible < 200, Moyen 200-500, Epidemique > 500\n",
    "2. Classifier les predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56be3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_risk(cases):\n",
    "    if cases < 200:\n",
    "        return 'Faible'\n",
    "    elif cases < 500:\n",
    "        return 'Moyen'\n",
    "    else:\n",
    "        return 'Epidemique'\n",
    "\n",
    "# Appliquer la classification\n",
    "df_original = pd.read_csv('epidemie.csv')\n",
    "df_original['Predicted_Risk'] = y_pred[:len(df_original)]\n",
    "df_original['Risk_Level'] = df_original['Predicted_Risk'].apply(classify_risk)\n",
    "\n",
    "print(\"Repartition des niveaux de risque :\")\n",
    "print(df_original['Risk_Level'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33744a",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Task 2: Identifier le Temps de Latence (Pluie -> Epidemie)\n",
    "\n",
    "**Goal:** Combien de semaines apres la pluie l epidemie eclate-t-elle ?\n",
    "\n",
    "**Approach:**\n",
    "1. Calculer correlation entre Precipitations et Cases avec differents lags\n",
    "2. Trouver le lag avec la correlation maximale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_original = pd.read_csv('epidemie.csv').dropna()\n",
    "df_original = df_original.sort_values('Week').reset_index(drop=True)\n",
    "\n",
    "# Tester differents lags (0 a 8 semaines)\n",
    "correlations = []\n",
    "for lag in range(9):\n",
    "    df_original[f'Precip_Lag{lag}'] = df_original['Precipitations'].shift(lag)\n",
    "    corr = df_original['Cases'].corr(df_original[f'Precip_Lag{lag}'])\n",
    "    correlations.append((lag, corr))\n",
    "    print(f\"Lag {lag} semaines : Correlation = {corr:.3f}\")\n",
    "\n",
    "# Trouver le meilleur lag\n",
    "best_lag = max(correlations, key=lambda x: abs(x[1]) if not np.isnan(x[1]) else 0)\n",
    "print(f\"\\nTemps de latence optimal : {best_lag[0]} semaines\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7587b7",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Task 3: Corréler Google Trends avec Données Officielles\n",
    "\n",
    "**Goal:** Google Trends est-il un bon indicateur précoce ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_original = pd.read_csv('epidemie.csv').dropna()\n",
    "\n",
    "correlation = df_original['Google_Trends'].corr(df_original['Cases'])\n",
    "\n",
    "print(f\"Correlation Google Trends vs Cases : {correlation:.3f}\")\n",
    "\n",
    "if correlation > 0.7:\n",
    "    print(\"Google Trends est un EXCELLENT indicateur précoce !\")\n",
    "elif correlation > 0.5:\n",
    "    print(\"Google Trends est utile mais pas parfait.\")\n",
    "else:\n",
    "    print(\"Google Trends n'est pas fiable pour ce dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ff52d",
   "metadata": {},
   "source": [
    "\n",
    "### Bonus Task 4: Allouer les Ressources Médicales\n",
    "\n",
    "**Goal:** Recommander l'allocation de lits d'hôpital par région.\n",
    "\n",
    "**Approach:**\n",
    "1. Prédire les cas pour la semaine prochaine par région\n",
    "2. Allouer 5% des cas prédits comme nombre de lits nécessaires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grouper par région et prédire\n",
    "df_original = pd.read_csv('epidemie.csv').dropna()\n",
    "\n",
    "avg_cases_by_region = df_original.groupby('Region')['Cases'].mean()\n",
    "\n",
    "print(\"Allocation des lits par region (5% des cas moyens) :\")\n",
    "for region, cases in avg_cases_by_region.items():\n",
    "    beds_needed = int(cases * 0.05)\n",
    "    print(f\"{region}: {beds_needed} lits\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
