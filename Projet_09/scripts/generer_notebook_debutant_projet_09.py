import nbformat as nbf

def create_notebook():
    nb = nbf.v4.new_notebook()
    
    # --- CONFIGURATION ---
    PROJECT_NUMBER = "09"
    PROJECT_TITLE = "Gravit√© des Accidents de la Route"
    DATASET_NAME = "accidents_route.csv"
    TARGET_COL = "Gravite"
    
    # --- CELLULES ---
    
    cells = []
    
    # 1. HEADER
    cells.append(nbf.v4.new_markdown_cell(f"""
# üéì PROJET {PROJECT_NUMBER} : {PROJECT_TITLE}

## üèÅ Objectif : Vision Z√©ro
Votre mission est d'analyser les accidents de la route pour comprendre ce qui rend un accident grave.
Nous allons construire un mod√®le capable de pr√©dire la **Gravit√©** (1 √† 4) d'un accident en fonction de la m√©t√©o, de la route et du v√©hicule.

---

## üìã Programme des 3 Sessions

### üïµÔ∏è‚Äç‚ôÄÔ∏è SESSION 1 : Enqu√™teur de Donn√©es (45 min)
- **Part 1 :** Chargement et Nettoyage (Attention aux coordonn√©es GPS !)
- **Part 2 :** Analyse Exploratoire (O√π sont les accidents ?)

### üèóÔ∏è SESSION 2 : Architecte de Features (45 min)
- **Part 1 :** Feature Engineering (G√©ographie & Cat√©gories)
- **Part 2 :** Pr√©paration finale pour l'IA

### ü§ñ SESSION 3 : Entra√Æneur d'IA (45 min)
- **Part 1 :** Entra√Ænement du Mod√®le (Classification)
- **Part 2 :** √âvaluation (On ne veut rater aucun accident grave !)
- **Part 3 :** Bonus (Points noirs & Recommandations)

---
"""))

    # --- SESSION 1 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üìã SESSION 1 : From Raw Data to Clean Insights
"""))

    # Part 1: Setup
    cells.append(nbf.v4.new_markdown_cell("""
## üõ†Ô∏è Part 1: The Setup
Commen√ßons par charger nos outils et les donn√©es.
"""))
    
    cells.append(nbf.v4.new_code_cell(f"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration pour voir toutes les colonnes
pd.set_option('display.max_columns', None)

# Chargement des donn√©es
df = pd.read_csv('{DATASET_NAME}')

print("‚úÖ Donn√©es charg√©es avec succ√®s !")
print(f"üìä Dimensions : {{df.shape[0]}} lignes, {{df.shape[1]}} colonnes")
df.head()
"""))

    # Part 2: Sanity Check
    cells.append(nbf.v4.new_markdown_cell("""
## üßπ Part 2: The Sanity Check
Les donn√©es r√©elles sont rarement parfaites. Nettoyons-les !

### 2.1 Valeurs Manquantes
"""))

    cells.append(nbf.v4.new_code_cell("""
# V√©rifions les valeurs manquantes
print(df.isnull().sum())

# Visualisons les manquants
plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title("Carte des Valeurs Manquantes")
plt.show()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
> **üí° Tip:** Pour la m√©t√©o manquante, nous allons utiliser le "Mode" (la valeur la plus fr√©quente).
"""))

    cells.append(nbf.v4.new_code_cell("""
# Remplacer les valeurs manquantes dans 'Meteo' par la valeur la plus fr√©quente
mode_meteo = df['Meteo'].mode()[0]
df['Meteo'].fillna(mode_meteo, inplace=True)

# V√©rification
print(f"Valeurs manquantes restantes dans Meteo : {df['Meteo'].isnull().sum()}")
"""))

    # Part 3: EDA
    cells.append(nbf.v4.new_markdown_cell("""
## üîç Part 3: Exploratory Data Analysis (EDA)
Analysons la cible : **Gravite**.
"""))

    cells.append(nbf.v4.new_code_cell(f"""
# Distribution de la Gravit√©
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='{TARGET_COL}', palette='Reds')
plt.title("Distribution de la Gravit√© des Accidents")
plt.xlabel("Niveau de Gravit√© (1=L√©ger, 4=Mortel)")
plt.ylabel("Nombre d'accidents")
plt.show()

print("‚ùì Question : Y a-t-il un d√©s√©quilibre de classe ? (Une gravit√© beaucoup plus fr√©quente ?)")
"""))

    # --- SESSION 2 ---
    cells.append(nbf.v4.new_markdown_cell("""
# üèóÔ∏è SESSION 2 : The Art of Feature Engineering
Transformons nos donn√©es brutes en informations utiles pour le mod√®le.
"""))

    # Recipe 5: Geography
    cells.append(nbf.v4.new_markdown_cell("""
### üó∫Ô∏è Recipe: Geography (Coordonn√©es GPS)
La colonne `Localisation` contient "Latitude, Longitude" sous forme de texte. L'ordinateur a besoin de deux colonnes num√©riques s√©par√©es.
"""))

    cells.append(nbf.v4.new_code_cell("""
# Exemple pour la premi√®re ligne
exemple = "34.2503, -6.8078"
lat, lon = exemple.split(', ')
print(f"Latitude: {lat}, Longitude: {lon}")

# Appliquons cela √† tout le dataset
# Nous utilisons une fonction lambda pour s√©parer la cha√Æne
df[['Latitude', 'Longitude']] = df['Localisation'].str.split(', ', expand=True).astype(float)

# Supprimons l'ancienne colonne
df.drop('Localisation', axis=1, inplace=True)

print("‚úÖ Coordonn√©es extraites !")
df[['Latitude', 'Longitude']].head()
"""))

    cells.append(nbf.v4.new_markdown_cell("""
> **‚ö†Ô∏è Warning:** Certaines coordonn√©es sont "0.0, 0.0". Ce sont probablement des erreurs (accidents en plein oc√©an !).
"""))

    cells.append(nbf.v4.new_code_cell("""
# Filtrons les coordonn√©es invalides (0, 0)
# On consid√®re que le Maroc est environ entre Lat 21-36 et Lon -17 √† -1
mask_valid = (df['Latitude'] != 0) & (df['Longitude'] != 0)
df_clean = df[mask_valid].copy()

print(f"Lignes avant nettoyage : {len(df)}")
print(f"Lignes apr√®s suppression des GPS 0.0 : {len(df_clean)}")
"""))

    # Recipe 2: Categories
    cells.append(nbf.v4.new_markdown_cell("""
### üè∑Ô∏è Recipe: Categories
Les mod√®les ne comprennent pas "Pluie" ou "Camion". Ils veulent des chiffres.
Utilisons le **Label Encoding** pour les variables ordonn√©es (si on en avait) ou **One-Hot Encoding** pour les cat√©gories nominales.
"""))

    cells.append(nbf.v4.new_code_cell("""
# Encodage One-Hot pour Meteo, Type_Route, Type_Vehicule
# pd.get_dummies cr√©e des colonnes binaires (0/1)
categorical_cols = ['Meteo', 'Type_Route', 'Type_Vehicule']
df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)

print("‚úÖ Encodage termin√© !")
df_encoded.head()
"""))

    # --- SESSION 3 ---
    cells.append(nbf.v4.new_markdown_cell("""
# ü§ñ SESSION 3 : Building & Trusting Your Model
C'est le moment d'entra√Æner notre IA !
"""))

    # Part 1: Split
    cells.append(nbf.v4.new_markdown_cell("""
## ‚úÇÔ∏è Part 1: The Split
S√©parons les donn√©es pour l'entra√Ænement et le test.
"""))

    cells.append(nbf.v4.new_code_cell(f"""
from sklearn.model_selection import train_test_split

X = df_encoded.drop(['ID_Accident', '{TARGET_COL}'], axis=1)
y = df_encoded['{TARGET_COL}']

# Split 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Train shape: {{X_train.shape}}")
print(f"Test shape: {{X_test.shape}}")
"""))

    # Part 2: Training (Imbalanced)
    cells.append(nbf.v4.new_markdown_cell("""
## üèãÔ∏è Part 2: Training (Gestion du D√©s√©quilibre)
Les accidents tr√®s graves (4) sont heureusement plus rares. Mais pour l'IA, c'est un probl√®me : elle risque de les ignorer.
Nous allons utiliser **SMOTE** pour cr√©er des exemples synth√©tiques des classes rares.
"""))

    cells.append(nbf.v4.new_code_cell("""
from imblearn.over_sampling import SMOTE

print("Avant SMOTE :")
print(y_train.value_counts().sort_index())

# Application de SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

print("\\nApr√®s SMOTE :")
print(y_train_balanced.value_counts().sort_index())
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.ensemble import RandomForestClassifier

# Entra√Ænement sur donn√©es √©quilibr√©es
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_balanced, y_train_balanced)

print("‚úÖ Mod√®le entra√Æn√© !")
"""))

    # Part 3: Evaluation
    cells.append(nbf.v4.new_markdown_cell("""
## üìä Part 3: Evaluation
Regardons si notre mod√®le arrive √† d√©tecter les accidents graves.
"""))

    cells.append(nbf.v4.new_code_cell("""
from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_test)

print("Rapport de Classification :")
print(classification_report(y_test, y_pred))

# Matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Matrice de Confusion")
plt.xlabel("Pr√©diction")
plt.ylabel("R√©alit√©")
plt.show()
"""))

    # Part 4: Bonus
    cells.append(nbf.v4.new_markdown_cell("""
## üéÅ Part 4: Going Further (Bonus)

### üåç Bonus Task 1: Identifier les "Points Noirs"
O√π sont concentr√©s les accidents ?
"""))

    cells.append(nbf.v4.new_code_cell("""
# Visualisation g√©ographique simple
plt.figure(figsize=(10, 8))
sns.scatterplot(data=df_clean, x='Longitude', y='Latitude', hue='Gravite', palette='viridis', alpha=0.6)
plt.title("Carte des Accidents par Gravit√©")
plt.show()

# TODO: Essayez d'identifier visuellement les zones denses (clusters)
"""))

    cells.append(nbf.v4.new_markdown_cell("""
### üåßÔ∏è Bonus Task 2: Impact de la Pluie
La pluie augmente-t-elle vraiment la gravit√© ?
"""))

    cells.append(nbf.v4.new_code_cell("""
# Tableau crois√© : M√©t√©o vs Gravit√©
# Note: On utilise df_clean avant encodage pour avoir les noms de m√©t√©o
crosstab = pd.crosstab(df_clean['Meteo'], df_clean['Gravite'], normalize='index')

# Visualisation
crosstab.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='RdYlGn_r')
plt.title("Proportion de Gravit√© par M√©t√©o")
plt.ylabel("Proportion")
plt.show()

print("‚ùì Question : La barre rouge (Gravit√© 4) est-elle plus grande quand il pleut ?")
"""))

    nb['cells'] = cells

    # Save notebook
    with open(f"Projet_{PROJECT_NUMBER}_Accidents_Debutant.ipynb", "w", encoding="utf-8") as f:
        nbf.write(nb, f)

if __name__ == "__main__":
    create_notebook()
