import nbformat as nbf

def generer_notebook_debutant():
    nb = nbf.v4.new_notebook()
    
    # Titre
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸš— PROJET 18 : POINTS CHAUDS DE COVOITURAGE ğŸ“

Bienvenue dans ce projet stratÃ©gique pour les plateformes de covoiturage !

**Le ProblÃ¨me :** Les chauffeurs roulent dans des rues vides pendant que des passagers attendent ailleurs. C'est du gaspillage de temps et de carburant !

**Votre Mission :** PrÃ©dire la demande de courses (Demandes) par zone et par heure. Ainsi, l'app peut envoyer les chauffeurs exactement lÃ  oÃ¹ sont les passagers ! ğŸ¯

---

## ğŸ“… VOTRE PROGRAMME

### ğŸ“‹ SESSION 1 : From Raw Data to Clean Insights (45 min)
- **Part 1: The Setup** - Charger les donnÃ©es historiques de courses
- **Part 2: The Sanity Check** - Nettoyer les donnÃ©es manquantes
- **Part 3: Exploratory Data Analysis** - OÃ¹ et quand la demande est-elle forte ?

### ğŸ“‹ SESSION 2 : The Art of Feature Engineering (45 min)
- **Part 1: The Concept** - Extraire des features temporelles
- **Part 2: The Lab** - CrÃ©er le ratio Offre/Demande
- **Part 3: Final Prep** - PrÃ©parer pour le modÃ¨le

### ğŸ“‹ SESSION 3 : Building & Trusting Your Model (45 min)
- **Part 1: The Split** - SÃ©parer train/test
- **Part 2: Training** - EntraÃ®ner le modÃ¨le de prÃ©diction
- **Part 3: Evaluation** - Mesurer la prÃ©cision
- **Part 4: Going Further (BONUS)** - Tarification dynamique et relocalisation

---
"""))

    # SESSION 1
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ“‹ SESSION 1 : FROM RAW DATA TO CLEAN INSIGHTS
"""))

    # Part 1
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ Part 1: The Setup (10 min)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

print("âœ… Librairies importÃ©es !")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### ğŸ“‚ Chargement du fichier covoiturage.csv
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df = pd.read_csv('covoiturage.csv')

print("AperÃ§u des donnÃ©es :")
display(df.head(10))

print("\\nInfos techniques :")
df.info()
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
> **ğŸ’¡ Tip:** Le dataset contient :
> - **ID_Zone** : Identifiant de la zone gÃ©ographique (1-10)
> - **Horodatage** : Date et heure (format datetime)
> - **Chauffeurs_Actifs** : Nombre de chauffeurs disponibles
> - **Meteo** : MÃ©tÃ©o (Clear, Rain)
> - **Evenements** : 1 si Ã©vÃ©nement spÃ©cial, 0 sinon
> - **Demandes** : ğŸ¯ NOTRE CIBLE (nombre de courses demandÃ©es)
"""))

    # Part 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ§¹ Part 2: The Sanity Check (15 min)

### 1. Valeurs manquantes
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
print("Valeurs manquantes par colonne :")
print(df.isnull().sum())
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
> **âš ï¸ Warning:** Nous avons des valeurs manquantes dans `Chauffeurs_Actifs` et `Meteo`. Pour simplifier, supprimons ces lignes.
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df = df.dropna()

print(f"âœ… Nouvelles dimensions : {df.shape}")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### 2. Conversion de l'horodatage
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df['Horodatage'] = pd.to_datetime(df['Horodatage'])
print("âœ… Horodatage converti !")
"""))

    # Part 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ“Š Part 3: Exploratory Data Analysis (20 min)

### ğŸ“ˆ Demande par Zone
Quelles zones sont les plus demandÃ©es ?
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(10, 5))
sns.barplot(data=df, x='ID_Zone', y='Demandes', estimator=np.mean, errorbar=None)
plt.title('Demande Moyenne par Zone')
plt.ylabel('Nombre de Courses DemandÃ©es')
plt.show()
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
â“ **Question :** Quelles zones ont la demande la plus Ã©levÃ©e ?

### ğŸŒ¦ï¸ Impact de la MÃ©tÃ©o
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
plt.figure(figsize=(8, 5))
sns.barplot(data=df, x='Meteo', y='Demandes', errorbar=None)
plt.title('Demande par MÃ©tÃ©o')
plt.show()
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
â“ **Question :** La pluie augmente-t-elle la demande de courses ?
"""))

    # SESSION 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ“‹ SESSION 2 : THE ART OF FEATURE ENGINEERING
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ§  Part 1: The Concept (10 min)

Pour prÃ©dire la demande, le modÃ¨le a besoin de :
- **L'heure de la journÃ©e** (rush du matin vs nuit calme)
- **Le jour de la semaine** (week-end vs jour de semaine)
- **Le ratio Offre/Demande** (Combien de chauffeurs pour combien de passagers ?)
"""))

    # Part 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ§ª Part 2: The Lab - Choose Your Recipe (30 min)

### Recipe 1: Dates & Time ğŸ•
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df['Heure'] = df['Horodatage'].dt.hour
df['JourSemaine'] = df['Horodatage'].dt.dayofweek
df['Mois'] = df['Horodatage'].dt.month
df['Is_Weekend'] = (df['JourSemaine'] >= 5).astype(int)

print("âœ… Features temporelles crÃ©Ã©es !")
display(df[['Horodatage', 'Heure', 'JourSemaine', 'Is_Weekend']].head())
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Recipe 2: Categories ğŸ·ï¸
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
df = pd.get_dummies(df, columns=['Meteo'], prefix='Meteo')

print("âœ… Encodage terminÃ© !")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Recipe 6: Domain-Specific Features ğŸ¯

#### ğŸ”¹ Ratio Offre/Demande
Si on a 100 chauffeurs pour 200 demandes, c'est une pÃ©nurie !
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# CrÃ©er le ratio (attention Ã  division par zÃ©ro)
df['Supply_Demand_Ratio'] = df['Chauffeurs_Actifs'] / (df['Demandes'] + 1)

print("âœ… Ratio Offre/Demande crÃ©Ã© !")
"""))

    # Part 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ Part 3: Final Prep (5 min)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
cols_to_drop = ['Horodatage']

df_model = df.drop(columns=cols_to_drop)
df_model = df_model.dropna()

print(f"âœ… Dataset prÃªt ! Dimensions : {df_model.shape}")
"""))

    # SESSION 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
# ğŸ“‹ SESSION 3 : BUILDING & TRUSTING YOUR MODEL
"""))

    # Part 1
    nb.cells.append(nbf.v4.new_markdown_cell("""
## âœ‚ï¸ Part 1: The Split (10 min)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
from sklearn.model_selection import train_test_split

X = df_model.drop('Demandes', axis=1)
y = df_model['Demandes']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Train size: {X_train.shape}")
print(f"Test size: {X_test.shape}")
"""))

    # Part 2
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ‹ï¸ Part 2: Training (15 min)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=42)

print("â³ EntraÃ®nement...")
model.fit(X_train, y_train)
print("âœ… ModÃ¨le entraÃ®nÃ© !")
"""))

    # Part 3
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ¯ Part 3: Evaluation (20 min)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"ğŸ“Š MAE (Erreur Moyenne) : {mae:.2f} courses")
print(f"ğŸ“Š RMSE : {rmse:.2f}")
print(f"ğŸ“Š RÂ² Score : {r2:.3f}")

# Visualisation
plt.figure(figsize=(8, 8))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Demandes RÃ©elles')
plt.ylabel('Demandes PrÃ©dites')
plt.title('VÃ©ritÃ© vs PrÃ©diction')
plt.show()
"""))

    # Part 4 Bonus
    nb.cells.append(nbf.v4.new_markdown_cell("""
## ğŸ Part 4: Going Further (Bonus - 15-30 mins)

### Bonus Task 1: Cartographier les Zones de Tarification Dynamique ğŸ’°

**Goal:** Identifier les zones oÃ¹ il faut augmenter les prix.

**Why it matters:** Quand la demande est HAUTE et l'offre est BASSE, on applique une "surge pricing" pour attirer plus de chauffeurs.

**Approach:**
1. DÃ©finir un seuil : Supply_Demand_Ratio < 0.5 (2 passagers pour 1 chauffeur)
2. Identifier ces moments par zone
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# TODO: Identifier les zones de tarification dynamique
df_original = pd.read_csv('covoiturage.csv').dropna()
df_original['Horodatage'] = pd.to_datetime(df_original['Horodatage'])
df_original['Supply_Demand_Ratio'] = df_original['Chauffeurs_Actifs'] / (df_original['Demandes'] + 1)

# Zones avec ratio < 0.5 (pÃ©nurie)
surge_zones = df_original[df_original['Supply_Demand_Ratio'] < 0.5]

print(f"ğŸ”¥ Nombre d'heures avec tarification dynamique : {len(surge_zones)}")
print("\\nTop 5 zones avec le plus de pÃ©nuries :")
print(surge_zones['ID_Zone'].value_counts().head())
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 2: Recommander la Relocalisation des Chauffeurs ğŸš™

**Goal:** Dire aux chauffeurs de se dÃ©placer des zones Ã  surplus vers les zones en dÃ©ficit.

**Approach:**
1. Identifier les zones avec trop de chauffeurs (Supply_Demand_Ratio > 2)
2. Identifier les zones en manque (Supply_Demand_Ratio < 0.5)
3. Recommandermouvement : Zone A â†’ Zone B
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Exemple : Ã  l'heure actuelle (derniÃ¨re heure du dataset)
current_hour = df_original.iloc[-10:]  # DerniÃ¨res 10 lignes

surplus_zones = current_hour[current_hour['Supply_Demand_Ratio'] > 2][['ID_Zone', 'Chauffeurs_Actifs', 'Demandes']]
deficit_zones = current_hour[current_hour['Supply_Demand_Ratio'] < 0.5][['ID_Zone', 'Chauffeurs_Actifs', 'Demandes']]

print("ğŸ“ˆ Zones avec SURPLUS de chauffeurs :")
print(surplus_zones)

print("\\nğŸ“‰ Zones en DÃ‰FICIT de chauffeurs :")
print(deficit_zones)

print("\\nğŸš— Recommandation : DÃ©placer les chauffeurs des zones en surplus vers les zones en dÃ©ficit.")
"""))

    nb.cells.append(nbf.v4.new_markdown_cell("""
### Bonus Task 4: Regrouper les Zones par Type ğŸ˜ï¸

**Goal:** Classifier chaque zone : RÃ©sidentielle, Affaires, ou Vie Nocturne.

**Approach:**
- **RÃ©sidentielle** : Pic de demande le matin (7h-9h) et soir (18h-20h)
- **Affaires** : Demande Ã©levÃ©e en journÃ©e (9h-18h)
- **Vie Nocturne** : Pic de demande la nuit (22h-2h)
"""))

    nb.cells.append(nbf.v4.new_code_cell("""
# Calculer la demande moyenne par zone et par heure
df_original['Heure'] = df_original['Horodatage'].dt.hour

demand_by_zone_hour = df_original.groupby(['ID_Zone', 'Heure'])['Demandes'].mean().reset_index()

# Pour chaque zone, identifier l'heure de pic
peak_hours = demand_by_zone_hour.loc[demand_by_zone_hour.groupby('ID_Zone')['Demandes'].idxmax()]

print("Heure de pic par zone :")
print(peak_hours)

# Classification simplifiÃ©e
def classify_zone(peak_hour):
    if 7 <= peak_hour <= 9 or 18 <= peak_hour <= 20:
        return 'RÃ©sidentielle ğŸ¡'
    elif 9 < peak_hour < 18:
        return 'Affaires ğŸ’¼'
    else:
        return 'Vie Nocturne ğŸ‰'

peak_hours['Type_Zone'] = peak_hours['Heure'].apply(classify_zone)

print("\\nClassification des zones :")
print(peak_hours[['ID_Zone', 'Heure', 'Type_Zone']])
"""))

    # Sauvegarde
    with open('Projet_18_Covoiturage_Debutant.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)

if __name__ == "__main__":
    generer_notebook_debutant()
